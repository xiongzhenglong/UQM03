This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: uqm-backend/src/api/models.py, uqm-backend/src/api/routes.py, uqm-backend/src/config/settings.py, uqm-backend/src/connectors/base.py, uqm-backend/src/connectors/mysql.py, uqm-backend/src/connectors/postgres.py, uqm-backend/src/connectors/sqlite.py, uqm-backend/src/core/cache.py, uqm-backend/src/core/engine.py, uqm-backend/src/core/executor.py, uqm-backend/src/core/parser.py, uqm-backend/src/steps/assert_step.py, uqm-backend/src/steps/base.py, uqm-backend/src/steps/enrich_step.py, uqm-backend/src/steps/pivot_step.py, uqm-backend/src/steps/query_step.py, uqm-backend/src/steps/union_step.py, uqm-backend/src/steps/unpivot_step.py, uqm-backend/src/utils/exceptions.py, uqm-backend/src/utils/expression_parser.py, uqm-backend/src/utils/logging.py, uqm-backend/src/utils/sql_builder.py, uqm-backend/src/utils/validators.py, uqm-backend/src/__version__.py, uqm-backend/src/main.py
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)


================================================================
Directory Structure
================================================================
uqm-backend/src/__version__.py
uqm-backend/src/api/models.py
uqm-backend/src/api/routes.py
uqm-backend/src/config/settings.py
uqm-backend/src/connectors/base.py
uqm-backend/src/connectors/mysql.py
uqm-backend/src/connectors/postgres.py
uqm-backend/src/connectors/sqlite.py
uqm-backend/src/core/cache.py
uqm-backend/src/core/engine.py
uqm-backend/src/core/executor.py
uqm-backend/src/core/parser.py
uqm-backend/src/main.py
uqm-backend/src/steps/assert_step.py
uqm-backend/src/steps/base.py
uqm-backend/src/steps/enrich_step.py
uqm-backend/src/steps/pivot_step.py
uqm-backend/src/steps/query_step.py
uqm-backend/src/steps/union_step.py
uqm-backend/src/steps/unpivot_step.py
uqm-backend/src/utils/exceptions.py
uqm-backend/src/utils/expression_parser.py
uqm-backend/src/utils/logging.py
uqm-backend/src/utils/sql_builder.py
uqm-backend/src/utils/validators.py

================================================================
Files
================================================================

================
File: uqm-backend/src/__version__.py
================
"""
版本信息
"""

__version__ = "1.0.0"
__version_info__ = (1, 0, 0)
__author__ = "UQM Team"
__email__ = "team@uqm.com"
__description__ = "统一查询模型（UQM）后端执行引擎"

================
File: uqm-backend/src/api/models.py
================
"""
Pydantic数据模型定义
定义API请求和响应的数据结构
"""

from typing import Any, Dict, List, Optional, Union
from datetime import datetime
from enum import Enum

from pydantic import BaseModel, Field, validator


class StepType(str, Enum):
    """步骤类型枚举"""
    QUERY = "query"
    ENRICH = "enrich"
    PIVOT = "pivot"
    UNPIVOT = "unpivot"
    UNION = "union"
    ASSERT = "assert"


class JobStatus(str, Enum):
    """异步任务状态枚举"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


class Parameter(BaseModel):
    """参数定义模型"""
    name: str = Field(..., description="参数名称")
    type: str = Field(..., description="参数类型")
    default: Optional[Any] = Field(None, description="默认值")
    required: bool = Field(True, description="是否必需")
    description: Optional[str] = Field(None, description="参数描述")


class Metadata(BaseModel):
    """元数据模型"""
    name: str = Field(..., description="查询名称")
    description: Optional[str] = Field(None, description="查询描述")
    version: Optional[str] = Field("1.0", description="版本号")
    author: Optional[str] = Field(None, description="作者")
    created_at: Optional[datetime] = Field(None, description="创建时间")
    updated_at: Optional[datetime] = Field(None, description="更新时间")
    tags: Optional[List[str]] = Field(default_factory=list, description="标签列表")


class StepResult(BaseModel):
    """单个步骤执行结果模型"""
    step_name: str = Field(..., description="步骤名称")
    step_type: StepType = Field(..., description="步骤类型")
    status: str = Field(..., description="执行状态")
    data: Optional[List[Dict[str, Any]]] = Field(None, description="步骤结果数据")
    row_count: int = Field(0, description="结果行数")
    execution_time: float = Field(0.0, description="执行时间(秒)")
    cache_hit: bool = Field(False, description="是否命中缓存")
    error: Optional[str] = Field(None, description="错误信息")


class ValidationError(BaseModel):
    """验证错误详情模型"""
    field: str = Field(..., description="错误字段")
    message: str = Field(..., description="错误信息")
    value: Optional[Any] = Field(None, description="错误值")


class ErrorResponse(BaseModel):
    """错误响应模型"""
    error: Dict[str, Any] = Field(..., description="错误详情")
    
    class Config:
        schema_extra = {
            "example": {
                "error": {
                    "code": "VALIDATION_ERROR",
                    "message": "数据验证失败",
                    "details": {}
                }
            }
        }


class UQMRequest(BaseModel):
    """UQM请求数据模型"""
    uqm: Dict[str, Any] = Field(..., description="UQM JSON定义")
    parameters: Optional[Dict[str, Any]] = Field(default_factory=dict, description="查询参数")
    options: Optional[Dict[str, Any]] = Field(default_factory=dict, description="执行选项")
    
    @validator('uqm')
    def validate_uqm(cls, v):
        """验证UQM结构"""
        if not isinstance(v, dict):
            raise ValueError("UQM必须是一个JSON对象")
        
        required_fields = ['metadata', 'steps']
        for field in required_fields:
            if field not in v:
                raise ValueError(f"UQM缺少必需字段: {field}")
        
        return v
    
    class Config:
        schema_extra = {
            "example": {
                "uqm": {
                    "metadata": {
                        "name": "示例查询",
                        "description": "这是一个示例UQM查询"
                    },
                    "steps": [
                        {
                            "name": "step1",
                            "type": "query",
                            "config": {
                                "data_source": "users",
                                "dimensions": ["id", "name"],
                                "metrics": [],
                                "filters": []
                            }
                        }
                    ],
                    "output": "step1"
                },
                "parameters": {
                    "limit": 100
                },
                "options": {
                    "cache_enabled": True,
                    "timeout": 300
                }
            }
        }


class UQMResponse(BaseModel):
    """UQM响应数据模型"""
    success: bool = Field(..., description="执行是否成功")
    data: Optional[List[Dict[str, Any]]] = Field(None, description="查询结果数据")
    metadata: Optional[Metadata] = Field(None, description="查询元数据")
    execution_info: Dict[str, Any] = Field(default_factory=dict, description="执行信息")
    step_results: Optional[List[StepResult]] = Field(None, description="步骤执行结果")
    
    class Config:
        schema_extra = {
            "example": {
                "success": True,
                "data": [
                    {"id": 1, "name": "张三"},
                    {"id": 2, "name": "李四"}
                ],
                "metadata": {
                    "name": "示例查询",
                    "description": "这是一个示例UQM查询"
                },
                "execution_info": {
                    "total_time": 1.23,
                    "row_count": 2,
                    "cache_hit": False
                },
                "step_results": [
                    {
                        "step_name": "step1",
                        "step_type": "query",
                        "status": "completed",
                        "row_count": 2,
                        "execution_time": 1.23,
                        "cache_hit": False
                    }
                ]
            }
        }


class ValidationRequest(BaseModel):
    """验证请求模型"""
    uqm: Dict[str, Any] = Field(..., description="要验证的UQM JSON定义")
    
    class Config:
        schema_extra = {
            "example": {
                "uqm": {
                    "metadata": {
                        "name": "示例查询"
                    },
                    "steps": [
                        {
                            "name": "step1",
                            "type": "query",
                            "config": {}
                        }
                    ],
                    "output": "step1"
                }
            }
        }


class ValidationResponse(BaseModel):
    """验证响应模型"""
    valid: bool = Field(..., description="是否验证通过")
    errors: Optional[List[ValidationError]] = Field(None, description="验证错误列表")
    warnings: Optional[List[str]] = Field(None, description="警告信息列表")
    
    class Config:
        schema_extra = {
            "example": {
                "valid": True,
                "errors": None,
                "warnings": ["建议添加查询描述"]
            }
        }


class HealthResponse(BaseModel):
    """健康检查响应模型"""
    status: str = Field(..., description="服务状态")
    timestamp: datetime = Field(..., description="检查时间")
    version: str = Field(..., description="服务版本")
    uptime: float = Field(..., description="运行时间(秒)")
    
    class Config:
        schema_extra = {
            "example": {
                "status": "healthy",
                "timestamp": "2023-12-01T10:00:00Z",
                "version": "0.1.0",
                "uptime": 3600.0
            }
        }


class MetricsResponse(BaseModel):
    """指标响应模型"""
    total_requests: int = Field(..., description="总请求数")
    successful_requests: int = Field(..., description="成功请求数")
    failed_requests: int = Field(..., description="失败请求数")
    average_response_time: float = Field(..., description="平均响应时间(秒)")
    active_connections: int = Field(..., description="活跃连接数")
    cache_hit_rate: float = Field(..., description="缓存命中率")
    
    class Config:
        schema_extra = {
            "example": {
                "total_requests": 1000,
                "successful_requests": 950,
                "failed_requests": 50,
                "average_response_time": 1.5,
                "active_connections": 10,
                "cache_hit_rate": 0.75
            }
        }


class AsyncJobRequest(BaseModel):
    """异步任务请求模型"""
    uqm: Dict[str, Any] = Field(..., description="UQM JSON定义")
    parameters: Optional[Dict[str, Any]] = Field(default_factory=dict, description="查询参数")
    callback_url: Optional[str] = Field(None, description="结果回调URL")
    
    class Config:
        schema_extra = {
            "example": {
                "uqm": {
                    "metadata": {"name": "异步查询"},
                    "steps": [{"name": "step1", "type": "query", "config": {}}],
                    "output": "step1"
                },
                "parameters": {},
                "callback_url": "https://example.com/callback"
            }
        }


class AsyncJobResponse(BaseModel):
    """异步任务响应模型"""
    job_id: str = Field(..., description="任务ID")
    status: JobStatus = Field(..., description="任务状态")
    created_at: datetime = Field(..., description="创建时间")
    estimated_completion: Optional[datetime] = Field(None, description="预计完成时间")
    
    class Config:
        schema_extra = {
            "example": {
                "job_id": "job_123456",
                "status": "pending",
                "created_at": "2023-12-01T10:00:00Z",
                "estimated_completion": "2023-12-01T10:05:00Z"
            }
        }


class JobStatusResponse(BaseModel):
    """任务状态响应模型"""
    job_id: str = Field(..., description="任务ID")
    status: JobStatus = Field(..., description="任务状态")
    created_at: datetime = Field(..., description="创建时间")
    started_at: Optional[datetime] = Field(None, description="开始时间")
    completed_at: Optional[datetime] = Field(None, description="完成时间")
    progress: Optional[float] = Field(None, description="进度百分比")
    result: Optional[UQMResponse] = Field(None, description="执行结果")
    error: Optional[str] = Field(None, description="错误信息")
    
    class Config:
        schema_extra = {
            "example": {
                "job_id": "job_123456",
                "status": "completed",
                "created_at": "2023-12-01T10:00:00Z",
                "started_at": "2023-12-01T10:00:01Z",
                "completed_at": "2023-12-01T10:02:30Z",
                "progress": 100.0,
                "result": {
                    "success": True,
                    "data": [{"id": 1, "name": "张三"}]
                }
            }
        }

================
File: uqm-backend/src/api/routes.py
================
"""
REST API路由定义
定义所有API端点和处理逻辑
"""

import time
import uuid
from datetime import datetime, timedelta
from typing import Dict, Any

from fastapi import APIRouter, HTTPException, BackgroundTasks, Depends
from fastapi.responses import JSONResponse

from src.api.models import (
    UQMRequest, UQMResponse, ValidationRequest, ValidationResponse,
    HealthResponse, MetricsResponse, ErrorResponse,
    AsyncJobRequest, AsyncJobResponse, JobStatusResponse,
    JobStatus
)
from src.core.engine import get_uqm_engine
from src.core.cache import get_cache_manager
from src.utils.logging import get_logger
from src.utils.exceptions import (
    ValidationError, ExecutionError, TimeoutError
)
from src.config.settings import get_settings

# 创建路由实例
router = APIRouter()
logger = get_logger(__name__)

# 服务启动时间
START_TIME = time.time()

# 异步任务存储（生产环境应使用Redis或数据库）
async_jobs: Dict[str, Dict[str, Any]] = {}

# 指标统计
metrics = {
    "total_requests": 0,
    "successful_requests": 0,
    "failed_requests": 0,
    "total_response_time": 0.0,
    "active_connections": 0,
    "cache_hits": 0,
    "cache_misses": 0
}


def update_metrics(success: bool, response_time: float, cache_hit: bool = False) -> None:
    """更新指标统计"""
    metrics["total_requests"] += 1
    metrics["total_response_time"] += response_time
    
    if success:
        metrics["successful_requests"] += 1
    else:
        metrics["failed_requests"] += 1
    
    if cache_hit:
        metrics["cache_hits"] += 1
    else:
        metrics["cache_misses"] += 1


@router.post(
    "/execute",
    response_model=UQMResponse,
    summary="执行UQM查询",
    description="执行UQM查询并返回结果",
    responses={
        400: {"model": ErrorResponse, "description": "请求参数错误"},
        500: {"model": ErrorResponse, "description": "服务器内部错误"}
    }
)
async def execute_uqm(request: UQMRequest) -> UQMResponse:
    """
    执行UQM查询的主要端点
    
    Args:
        request: UQM请求数据
        
    Returns:
        UQM执行结果
    """
    start_time = time.time()
    
    try:
        logger.info(
            "开始执行UQM查询",
            uqm_name=request.uqm.get("metadata", {}).get("name", "未命名"),
            parameters=request.parameters
        )
        
        # 获取UQM引擎实例
        engine = get_uqm_engine()
        
        # 执行查询
        result = await engine.process(
            uqm_data=request.uqm,
            parameters=request.parameters,
            options=request.options
        )
        
        response_time = time.time() - start_time
        update_metrics(success=True, response_time=response_time)
        
        logger.info(
            "UQM查询执行完成",
            execution_time=response_time,
            row_count=len(result.data) if result.data else 0
        )
        
        return result
        
    except ValidationError as e:
        response_time = time.time() - start_time
        update_metrics(success=False, response_time=response_time)
        
        logger.error(
            "UQM查询验证失败",
            error=str(e),
            execution_time=response_time
        )
        
        raise HTTPException(
            status_code=400,
            detail={
                "code": "VALIDATION_ERROR",
                "message": str(e),
                "details": e.details
            }
        )
        
    except ExecutionError as e:
        response_time = time.time() - start_time
        update_metrics(success=False, response_time=response_time)
        
        logger.error(
            "UQM查询执行失败",
            error=str(e),
            execution_time=response_time
        )
        
        raise HTTPException(
            status_code=500,
            detail={
                "code": "EXECUTION_ERROR",
                "message": str(e),
                "details": e.details
            }
        )
        
    except TimeoutError as e:
        response_time = time.time() - start_time
        update_metrics(success=False, response_time=response_time)
        
        logger.error(
            "UQM查询执行超时",
            error=str(e),
            execution_time=response_time
        )
        
        raise HTTPException(
            status_code=408,
            detail={
                "code": "TIMEOUT_ERROR",
                "message": str(e),
                "details": e.details
            }
        )
        
    except Exception as e:
        response_time = time.time() - start_time
        update_metrics(success=False, response_time=response_time)
        
        logger.error(
            "UQM查询执行出现未知错误",
            error=str(e),
            execution_time=response_time,
            exc_info=True
        )
        
        raise HTTPException(
            status_code=500,
            detail={
                "code": "INTERNAL_ERROR",
                "message": "服务器内部错误",
                "details": {}
            }
        )


@router.post(
    "/validate",
    response_model=ValidationResponse,
    summary="验证UQM定义",
    description="验证UQM定义的有效性",
    responses={
        400: {"model": ErrorResponse, "description": "请求参数错误"}
    }
)
async def validate_uqm(request: ValidationRequest) -> ValidationResponse:
    """
    验证UQM定义有效性
    
    Args:
        request: 验证请求数据
        
    Returns:
        验证结果
    """
    try:
        logger.info(
            "开始验证UQM定义",
            uqm_name=request.uqm.get("metadata", {}).get("name", "未命名")
        )
        
        # 获取UQM引擎实例
        engine = get_uqm_engine()
        
        # 验证UQM定义
        validation_result = await engine.validate_query(request.uqm)
        
        logger.info(
            "UQM定义验证完成",
            valid=validation_result.valid,
            error_count=len(validation_result.errors) if validation_result.errors else 0
        )
        
        return validation_result
        
    except Exception as e:
        logger.error(
            "UQM定义验证出现错误",
            error=str(e),
            exc_info=True
        )
        
        raise HTTPException(
            status_code=500,
            detail={
                "code": "VALIDATION_ERROR",
                "message": "验证过程出现错误",
                "details": {"error": str(e)}
            }
        )


@router.get(
    "/health",
    response_model=HealthResponse,
    summary="健康检查",
    description="检查服务健康状态"
)
async def health_check() -> HealthResponse:
    """
    健康检查端点
    
    Returns:
        服务健康状态
    """
    uptime = time.time() - START_TIME
    
    return HealthResponse(
        status="healthy",
        timestamp=datetime.utcnow(),
        version="0.1.0",
        uptime=uptime
    )


@router.get(
    "/metrics",
    response_model=MetricsResponse,
    summary="获取系统指标",
    description="获取系统运行指标和统计信息"
)
async def get_metrics() -> MetricsResponse:
    """
    获取系统指标
    
    Returns:
        系统指标数据
    """
    # 计算缓存命中率
    total_cache_requests = metrics["cache_hits"] + metrics["cache_misses"]
    cache_hit_rate = (
        metrics["cache_hits"] / total_cache_requests 
        if total_cache_requests > 0 else 0.0
    )
    
    # 计算平均响应时间
    avg_response_time = (
        metrics["total_response_time"] / metrics["total_requests"]
        if metrics["total_requests"] > 0 else 0.0
    )
    
    return MetricsResponse(
        total_requests=metrics["total_requests"],
        successful_requests=metrics["successful_requests"],
        failed_requests=metrics["failed_requests"],
        average_response_time=avg_response_time,
        active_connections=metrics["active_connections"],
        cache_hit_rate=cache_hit_rate
    )


async def execute_async_job(job_id: str, uqm_data: Dict[str, Any], 
                          parameters: Dict[str, Any], callback_url: str = None) -> None:
    """
    执行异步任务
    
    Args:
        job_id: 任务ID
        uqm_data: UQM数据
        parameters: 查询参数
        callback_url: 回调URL
    """
    try:
        # 更新任务状态为运行中
        async_jobs[job_id].update({
            "status": JobStatus.RUNNING,
            "started_at": datetime.utcnow(),
            "progress": 0.0
        })
        
        logger.info(f"开始执行异步任务: {job_id}")
        
        # 获取UQM引擎实例
        engine = get_uqm_engine()
        
        # 执行查询
        result = await engine.process(
            uqm_data=uqm_data,
            parameters=parameters
        )
        
        # 更新任务状态为完成
        async_jobs[job_id].update({
            "status": JobStatus.COMPLETED,
            "completed_at": datetime.utcnow(),
            "progress": 100.0,
            "result": result
        })
        
        logger.info(f"异步任务执行完成: {job_id}")
        
        # 如果有回调URL，发送结果（这里简化处理）
        if callback_url:
            logger.info(f"发送回调通知: {callback_url}")
        
    except Exception as e:
        # 更新任务状态为失败
        async_jobs[job_id].update({
            "status": JobStatus.FAILED,
            "completed_at": datetime.utcnow(),
            "error": str(e)
        })
        
        logger.error(f"异步任务执行失败: {job_id}", error=str(e), exc_info=True)


@router.post(
    "/execute-async",
    response_model=AsyncJobResponse,
    summary="异步执行UQM查询",
    description="异步执行UQM查询，返回任务ID",
    responses={
        400: {"model": ErrorResponse, "description": "请求参数错误"}
    }
)
async def execute_async(request: AsyncJobRequest, background_tasks: BackgroundTasks) -> AsyncJobResponse:
    """
    异步执行UQM查询
    
    Args:
        request: 异步任务请求
        background_tasks: 后台任务
        
    Returns:
        异步任务响应
    """
    try:
        # 生成任务ID
        job_id = str(uuid.uuid4())
        
        # 创建任务记录
        created_at = datetime.utcnow()
        async_jobs[job_id] = {
            "job_id": job_id,
            "status": JobStatus.PENDING,
            "created_at": created_at,
            "uqm_data": request.uqm,
            "parameters": request.parameters,
            "callback_url": request.callback_url
        }
        
        # 添加后台任务
        background_tasks.add_task(
            execute_async_job,
            job_id=job_id,
            uqm_data=request.uqm,
            parameters=request.parameters,
            callback_url=request.callback_url
        )
        
        logger.info(f"创建异步任务: {job_id}")
        
        return AsyncJobResponse(
            job_id=job_id,
            status=JobStatus.PENDING,
            created_at=created_at,
            estimated_completion=created_at + timedelta(minutes=5)
        )
        
    except Exception as e:
        logger.error("创建异步任务失败", error=str(e), exc_info=True)
        
        raise HTTPException(
            status_code=500,
            detail={
                "code": "ASYNC_JOB_ERROR",
                "message": "创建异步任务失败",
                "details": {"error": str(e)}
            }
        )


@router.get(
    "/jobs/{job_id}",
    response_model=JobStatusResponse,
    summary="获取异步任务状态",
    description="获取指定任务的执行状态和结果",
    responses={
        404: {"model": ErrorResponse, "description": "任务不存在"}
    }
)
async def get_job_status(job_id: str) -> JobStatusResponse:
    """
    获取异步任务状态
    
    Args:
        job_id: 任务ID
        
    Returns:
        任务状态信息
    """
    if job_id not in async_jobs:
        raise HTTPException(
            status_code=404,
            detail={
                "code": "JOB_NOT_FOUND",
                "message": f"任务不存在: {job_id}",
                "details": {}
            }
        )
    
    job_info = async_jobs[job_id]
    
    return JobStatusResponse(
        job_id=job_id,
        status=job_info["status"],
        created_at=job_info["created_at"],
        started_at=job_info.get("started_at"),
        completed_at=job_info.get("completed_at"),
        progress=job_info.get("progress"),
        result=job_info.get("result"),
        error=job_info.get("error")
    )


@router.delete(
    "/jobs/{job_id}",
    summary="取消异步任务",
    description="取消指定的异步任务",
    responses={
        404: {"model": ErrorResponse, "description": "任务不存在"}
    }
)
async def cancel_job(job_id: str) -> Dict[str, str]:
    """
    取消异步任务
    
    Args:
        job_id: 任务ID
        
    Returns:
        取消结果
    """
    if job_id not in async_jobs:
        raise HTTPException(
            status_code=404,
            detail={
                "code": "JOB_NOT_FOUND",
                "message": f"任务不存在: {job_id}",
                "details": {}
            }
        )
    
    job_info = async_jobs[job_id]
    
    if job_info["status"] in [JobStatus.COMPLETED, JobStatus.FAILED]:
        raise HTTPException(
            status_code=400,
            detail={
                "code": "JOB_ALREADY_FINISHED",
                "message": f"任务已完成，无法取消: {job_id}",
                "details": {}
            }
        )
    
    # 更新任务状态为已取消
    async_jobs[job_id].update({
        "status": JobStatus.CANCELLED,
        "completed_at": datetime.utcnow()
    })
    
    logger.info(f"取消异步任务: {job_id}")
    
    return {"message": f"任务已取消: {job_id}"}

================
File: uqm-backend/src/config/settings.py
================
"""
应用程序配置管理模块
负责加载和管理所有配置项
"""

import os
from typing import List, Optional
from functools import lru_cache

from pydantic import Field
from pydantic_settings import BaseSettings, SettingsConfigDict


class Settings(BaseSettings):
    """应用程序配置类"""
    
    # 基础配置
    DEBUG: bool = Field(default=False, description="调试模式开关")
    HOST: str = Field(default="0.0.0.0", description="服务器主机地址")
    PORT: int = Field(default=8000, description="服务器端口")
    SECRET_KEY: str = Field(default="change-me-in-production", description="应用程序密钥")
    
    # 数据库配置
    DATABASE_URL: Optional[str] = Field(default=None, description="主数据库连接URL")
    MYSQL_URL: Optional[str] = Field(default=None, description="MySQL数据库连接URL")
    SQLITE_URL: Optional[str] = Field(default="sqlite:///./uqm.db", description="SQLite数据库连接URL")
    
    # Redis配置
    REDIS_URL: str = Field(default="redis://localhost:6379/0", description="Redis连接URL")
    
    # 缓存配置
    CACHE_TYPE: str = Field(default="memory", description="缓存类型")
    CACHE_DEFAULT_TIMEOUT: int = Field(default=3600, description="默认缓存超时时间(秒)")
    CACHE_MAX_SIZE: int = Field(default=1000, description="内存缓存最大条目数")
    
    # 日志配置
    LOG_LEVEL: str = Field(default="INFO", description="日志级别")
    LOG_FORMAT: str = Field(default="json", description="日志格式")
    
    # 查询配置
    MAX_QUERY_TIMEOUT: int = Field(default=300, description="最大查询超时时间(秒)")
    MAX_CONCURRENT_QUERIES: int = Field(default=10, description="最大并发查询数")
    QUERY_RESULT_LIMIT: int = Field(default=10000, description="查询结果行数限制")
    
    # 安全配置
    ALLOWED_HOSTS: List[str] = Field(default=["localhost", "127.0.0.1"], description="允许的主机列表")
    CORS_ORIGINS: List[str] = Field(default=[], description="CORS允许的源")
    CORS_CREDENTIALS: bool = Field(default=True, description="CORS是否允许凭证")
    CORS_METHODS: List[str] = Field(default=["GET", "POST", "PUT", "DELETE", "OPTIONS"], description="CORS允许的HTTP方法")
    CORS_HEADERS: List[str] = Field(default=["*"], description="CORS允许的请求头")
    
    # 监控配置
    ENABLE_METRICS: bool = Field(default=True, description="是否启用指标监控")
    METRICS_PATH: str = Field(default="/metrics", description="指标接口路径")
    
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        case_sensitive=True,
        extra="ignore"
    )
    
    def get_database_config(self) -> dict:
        """获取数据库配置信息"""
        return {
            "postgresql": self.DATABASE_URL,
            "mysql": self.MYSQL_URL,
            "sqlite": self.SQLITE_URL,
        }
    
    def get_cache_config(self) -> dict:
        """获取缓存配置信息"""
        return {
            "type": self.CACHE_TYPE,
            "redis_url": self.REDIS_URL,
            "default_timeout": self.CACHE_DEFAULT_TIMEOUT,
            "max_size": self.CACHE_MAX_SIZE,
        }
    
    def get_logging_config(self) -> dict:
        """获取日志配置信息"""
        return {
            "level": self.LOG_LEVEL,
            "format": self.LOG_FORMAT,
        }
    
    def validate_config(self) -> bool:
        """验证配置有效性"""
        try:
            # 验证必需的配置项
            if not self.SECRET_KEY or self.SECRET_KEY == "change-me-in-production":
                if not self.DEBUG:
                    raise ValueError("生产环境必须设置有效的SECRET_KEY")
            
            # 验证数据库配置
            if not any([self.DATABASE_URL, self.MYSQL_URL, self.SQLITE_URL]):
                raise ValueError("至少需要配置一个数据库连接")
            
            # 验证端口范围
            if not (1 <= self.PORT <= 65535):
                raise ValueError("端口号必须在1-65535范围内")
            
            # 验证超时配置
            if self.MAX_QUERY_TIMEOUT <= 0:
                raise ValueError("查询超时时间必须大于0")
            
            # 验证并发配置
            if self.MAX_CONCURRENT_QUERIES <= 0:
                raise ValueError("最大并发查询数必须大于0")
            
            return True
            
        except ValueError as e:
            print(f"配置验证失败: {e}")
            return False


@lru_cache()
def get_settings() -> Settings:
    """获取配置实例(单例模式)"""
    settings = Settings()
    
    # 验证配置
    if not settings.validate_config():
        raise RuntimeError("配置验证失败，请检查配置文件")
    
    return settings

================
File: uqm-backend/src/connectors/base.py
================
"""
数据连接器基类
定义所有连接器的通用接口和基础功能
"""

from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional, Union
from functools import lru_cache

from src.utils.logging import LoggerMixin
from src.utils.exceptions import ConnectionError
from src.config.settings import get_settings


class BaseConnector(ABC, LoggerMixin):
    """数据连接器基类"""
    
    def __init__(self, connection_config: Dict[str, Any]):
        """
        初始化连接器
        
        Args:
            connection_config: 连接配置
        """
        self.connection_config = connection_config
        self.connection = None
        self.is_connected = False
    
    @abstractmethod
    async def connect(self) -> None:
        """建立数据库连接"""
        pass
    
    @abstractmethod
    async def execute_query(self, query: str, params: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """
        执行查询
        
        Args:
            query: SQL查询语句
            params: 查询参数
            
        Returns:
            查询结果
        """
        pass
    
    @abstractmethod
    async def close(self) -> None:
        """关闭连接"""
        pass
    
    async def execute_batch(self, queries: List[str]) -> List[List[Dict[str, Any]]]:
        """
        批量执行查询
        
        Args:
            queries: 查询语句列表
            
        Returns:
            批量查询结果
        """
        results = []
        for query in queries:
            result = await self.execute_query(query)
            results.append(result)
        return results
    
    async def test_connection(self) -> bool:
        """
        测试连接有效性
        
        Returns:
            连接是否有效
        """
        try:
            if not self.is_connected:
                await self.connect()
            
            # 执行简单查询测试连接
            await self.execute_query("SELECT 1")
            return True
            
        except Exception as e:
            self.log_error("连接测试失败", error=str(e))
            return False
    
    async def get_table_schema(self, table_name: str) -> Dict[str, Any]:
        """
        获取表结构信息
        
        Args:
            table_name: 表名
            
        Returns:
            表结构信息
        """
        # 默认实现，子类可以重写
        try:
            query = f"SELECT * FROM {table_name} LIMIT 0"
            await self.execute_query(query)
            return {"table_name": table_name, "columns": []}
        except Exception as e:
            self.log_error(f"获取表 {table_name} 结构失败", error=str(e))
            raise ConnectionError(f"获取表结构失败: {e}")
    
    async def get_available_tables(self) -> List[str]:
        """
        获取可用表列表
        
        Returns:
            表名列表
        """
        # 默认实现，子类可以重写
        return []
    
    def _handle_connection_error(self, error: Exception) -> None:
        """
        处理连接错误
        
        Args:
            error: 错误信息
        """
        self.log_error("数据库连接错误", error=str(error))
        self.is_connected = False
        raise ConnectionError(f"数据库连接失败: {error}")
    
    def _format_query_result(self, result: Any) -> List[Dict[str, Any]]:
        """
        格式化查询结果
        
        Args:
            result: 原始查询结果
            
        Returns:
            格式化后的结果
        """
        # 默认实现，子类可以重写
        if isinstance(result, list):
            return result
        return []


class BaseConnectorManager(LoggerMixin):
    """连接器管理器基类"""
    
    def __init__(self):
        """初始化连接器管理器"""
        self.connectors: Dict[str, BaseConnector] = {}
        self.settings = get_settings()
    
    def register_connector(self, name: str, connector: BaseConnector) -> None:
        """
        注册连接器
        
        Args:
            name: 连接器名称
            connector: 连接器实例
        """
        self.connectors[name] = connector
        self.log_info(f"连接器 {name} 注册成功")
    
    def get_connector(self, name: str) -> Optional[BaseConnector]:
        """
        获取连接器
        
        Args:
            name: 连接器名称
            
        Returns:
            连接器实例
        """
        return self.connectors.get(name)
    
    async def close_all(self) -> None:
        """关闭所有连接器"""
        for name, connector in self.connectors.items():
            try:
                await connector.close()
                self.log_info(f"连接器 {name} 已关闭")
            except Exception as e:
                self.log_error(f"关闭连接器 {name} 失败", error=str(e))


class DefaultConnectorManager(BaseConnectorManager):
    """默认连接器管理器实现"""
    
    def __init__(self):
        """初始化默认连接器管理器"""
        super().__init__()
        self._initialize_connectors()
    
    def _initialize_connectors(self) -> None:
        """初始化默认连接器"""
        try:
            # 导入具体的连接器实现
            from src.connectors.postgres import PostgresConnector
            from src.connectors.mysql import MySQLConnector
            from src.connectors.sqlite import SQLiteConnector
            
            # 获取数据库配置
            db_config = self.settings.get_database_config()
            
            # 注册PostgreSQL连接器
            if db_config.get("postgresql"):
                postgres_connector = PostgresConnector(db_config["postgresql"])
                self.register_connector("postgresql", postgres_connector)
            
            # 注册MySQL连接器
            if db_config.get("mysql"):
                mysql_connector = MySQLConnector(db_config["mysql"])
                self.register_connector("mysql", mysql_connector)
            
            # 注册SQLite连接器
            if db_config.get("sqlite"):
                sqlite_connector = SQLiteConnector(db_config["sqlite"])
                self.register_connector("sqlite", sqlite_connector)
            
            self.log_info("默认连接器初始化完成")
            
        except Exception as e:
            self.log_error("初始化默认连接器失败", error=str(e))
    
    async def get_default_connector(self) -> BaseConnector:
        """
        获取默认连接器
        
        Returns:
            默认连接器实例
        """
        # 优先级：PostgreSQL > MySQL > SQLite
        for connector_name in ["postgresql", "mysql", "sqlite"]:
            connector = self.get_connector(connector_name)
            if connector:
                # 测试连接
                if await connector.test_connection():
                    return connector
        
        raise ConnectionError("没有可用的数据库连接器")


# 全局连接器管理器实例
_connector_manager: Optional[BaseConnectorManager] = None


@lru_cache()
def get_connector_manager() -> BaseConnectorManager:
    """获取连接器管理器实例(单例模式)"""
    global _connector_manager
    
    if _connector_manager is None:
        _connector_manager = DefaultConnectorManager()
    
    return _connector_manager

================
File: uqm-backend/src/connectors/mysql.py
================
"""
MySQL数据库连接器
实现MySQL数据库的连接和查询功能
"""

import asyncio
from typing import Any, Dict, List, Optional
from urllib.parse import urlparse

import pymysql
from pymysql.connections import Connection

from src.connectors.base import BaseConnector
from src.utils.exceptions import ConnectionError


class MySQLConnector(BaseConnector):
    """MySQL连接器实现"""
    
    def __init__(self, connection_url: str):
        """
        初始化MySQL连接器
        
        Args:
            connection_url: MySQL连接URL
        """
        # 解析连接URL
        parsed_url = urlparse(connection_url)
        
        connection_config = {
            "host": parsed_url.hostname,
            "port": parsed_url.port or 3306,
            "database": parsed_url.path.lstrip('/'),
            "user": parsed_url.username,
            "password": parsed_url.password,
            "connection_url": connection_url
        }
        
        super().__init__(connection_config)
        self.connection: Optional[Connection] = None
    
    async def connect(self) -> None:
        """建立MySQL连接"""
        try:
            self.log_info("正在连接MySQL数据库", host=self.connection_config["host"])
            
            # 创建MySQL连接
            self.connection = pymysql.connect(
                host=self.connection_config["host"],
                port=self.connection_config["port"],
                user=self.connection_config["user"],
                password=self.connection_config["password"],
                database=self.connection_config["database"],
                charset='utf8mb4',
                cursorclass=pymysql.cursors.DictCursor,
                autocommit=True
            )
            
            # 测试连接
            with self.connection.cursor() as cursor:
                cursor.execute("SELECT VERSION()")
                version = cursor.fetchone()
                self.log_info("MySQL连接成功", version=version["VERSION()"])
            
            self.is_connected = True
            
        except Exception as e:
            self.log_error("MySQL连接失败", error=str(e))
            self._handle_connection_error(e)
    
    async def execute_query(self, query: str, params: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """
        执行MySQL查询
        
        Args:
            query: SQL查询语句
            params: 查询参数
            
        Returns:
            查询结果
        """
        if not self.is_connected or not self.connection:
            await self.connect()
        
        try:
            self.log_debug("执行MySQL查询", query=query[:200])
            
            with self.connection.cursor() as cursor:
                # 执行查询
                if params:
                    cursor.execute(query, params)
                else:
                    cursor.execute(query)
                
                # 获取结果
                if cursor.description:
                    # 有结果集的查询
                    result = cursor.fetchall()
                    if not isinstance(result, list):
                        result = [result] if result else []
                else:
                    # 没有结果集的查询
                    result = []
            
            self.log_debug(
                "MySQL查询执行完成",
                row_count=len(result)
            )
            
            return result
            
        except Exception as e:
            self.log_error("MySQL查询执行失败", error=str(e), query=query[:200])
            self._handle_mysql_error(e)
            raise ConnectionError(f"查询执行失败: {e}")
    
    async def close(self) -> None:
        """关闭MySQL连接"""
        try:
            if self.connection:
                self.connection.close()
                self.connection = None
            
            self.is_connected = False
            self.log_info("MySQL连接已关闭")
            
        except Exception as e:
            self.log_error("关闭MySQL连接失败", error=str(e))
    
    async def get_table_schema(self, table_name: str) -> Dict[str, Any]:
        """
        获取MySQL表结构信息
        
        Args:
            table_name: 表名
            
        Returns:
            表结构信息
        """
        try:
            query = """
            SELECT 
                COLUMN_NAME as column_name,
                DATA_TYPE as data_type,
                IS_NULLABLE as is_nullable,
                COLUMN_DEFAULT as column_default,
                COLUMN_KEY as column_key,
                EXTRA as extra
            FROM INFORMATION_SCHEMA.COLUMNS 
            WHERE TABLE_SCHEMA = DATABASE() 
            AND TABLE_NAME = %s
            ORDER BY ORDINAL_POSITION
            """
            
            result = await self.execute_query(query, [table_name])
            
            columns = []
            for row in result:
                columns.append({
                    "name": row["column_name"],
                    "type": row["data_type"],
                    "nullable": row["is_nullable"] == "YES",
                    "default": row["column_default"],
                    "key": row["column_key"],
                    "extra": row["extra"]
                })
            
            return {
                "table_name": table_name,
                "columns": columns
            }
            
        except Exception as e:
            self.log_error(f"获取MySQL表 {table_name} 结构失败", error=str(e))
            raise ConnectionError(f"获取表结构失败: {e}")
    
    async def get_available_tables(self) -> List[str]:
        """
        获取MySQL可用表列表
        
        Returns:
            表名列表
        """
        try:
            query = """
            SELECT TABLE_NAME as table_name
            FROM INFORMATION_SCHEMA.TABLES 
            WHERE TABLE_SCHEMA = DATABASE() 
            AND TABLE_TYPE = 'BASE TABLE'
            ORDER BY TABLE_NAME
            """
            
            result = await self.execute_query(query)
            tables = [row["table_name"] for row in result]
            
            self.log_info(f"获取到 {len(tables)} 个MySQL表")
            return tables
            
        except Exception as e:
            self.log_error("获取MySQL表列表失败", error=str(e))
            raise ConnectionError(f"获取表列表失败: {e}")
    
    def _optimize_query_for_mysql(self, query: str) -> str:
        """
        为MySQL优化查询
        
        Args:
            query: 原始查询
            
        Returns:
            优化后的查询
        """
        # MySQL特定的查询优化
        # 比如：
        # - 使用FORCE INDEX提示
        # - 优化LIMIT和OFFSET
        # - 使用MySQL特定的函数
        
        return query
    
    def _handle_mysql_error(self, error: Exception) -> None:
        """
        处理MySQL特定错误
        
        Args:
            error: 错误信息
        """
        error_msg = str(error)
        
        # 连接错误
        if "lost connection" in error_msg.lower() or "gone away" in error_msg.lower():
            self.is_connected = False
            self.log_error("MySQL连接断开")
        
        # 语法错误
        elif "syntax" in error_msg.lower():
            self.log_error("MySQL SQL语法错误", error=error_msg)
        
        # 表不存在
        elif "doesn't exist" in error_msg.lower():
            self.log_error("MySQL表不存在", error=error_msg)
        
        # 权限错误
        elif "access denied" in error_msg.lower():
            self.log_error("MySQL权限不足", error=error_msg)
        
        # 其他错误
        else:
            self.log_error("MySQL未知错误", error=error_msg)
    
    def _create_connection_string(self) -> str:
        """
        创建MySQL连接字符串
        
        Returns:
            连接字符串
        """
        config = self.connection_config
        return (
            f"mysql://{config['user']}:{config['password']}"
            f"@{config['host']}:{config['port']}/{config['database']}"
        )

================
File: uqm-backend/src/connectors/postgres.py
================
"""
PostgreSQL数据库连接器
实现PostgreSQL数据库的连接和查询功能
"""

import asyncio
from typing import Any, Dict, List, Optional
from urllib.parse import urlparse

import psycopg2
import psycopg2.extras
from psycopg2.pool import SimpleConnectionPool

from src.connectors.base import BaseConnector
from src.utils.exceptions import ConnectionError


class PostgresConnector(BaseConnector):
    """PostgreSQL连接器实现"""
    
    def __init__(self, connection_url: str):
        """
        初始化PostgreSQL连接器
        
        Args:
            connection_url: PostgreSQL连接URL
        """
        # 解析连接URL
        parsed_url = urlparse(connection_url)
        
        connection_config = {
            "host": parsed_url.hostname,
            "port": parsed_url.port or 5432,
            "database": parsed_url.path.lstrip('/'),
            "user": parsed_url.username,
            "password": parsed_url.password,
            "connection_url": connection_url
        }
        
        super().__init__(connection_config)
        self.connection_pool: Optional[SimpleConnectionPool] = None
    
    async def connect(self) -> None:
        """建立PostgreSQL连接"""
        try:
            self.log_info("正在连接PostgreSQL数据库", host=self.connection_config["host"])
            
            # 创建连接池
            self.connection_pool = SimpleConnectionPool(
                minconn=1,
                maxconn=10,
                host=self.connection_config["host"],
                port=self.connection_config["port"],
                database=self.connection_config["database"],
                user=self.connection_config["user"],
                password=self.connection_config["password"],
                cursor_factory=psycopg2.extras.RealDictCursor
            )
            
            # 测试连接
            conn = self.connection_pool.getconn()
            try:
                with conn.cursor() as cursor:
                    cursor.execute("SELECT version()")
                    version = cursor.fetchone()
                self.log_info("PostgreSQL连接成功", version=version["version"])
            finally:
                self.connection_pool.putconn(conn)
            
            self.is_connected = True
            
        except Exception as e:
            self.log_error("PostgreSQL连接失败", error=str(e))
            self._handle_connection_error(e)
    
    async def execute_query(self, query: str, params: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """
        执行PostgreSQL查询
        
        Args:
            query: SQL查询语句
            params: 查询参数
            
        Returns:
            查询结果
        """
        if not self.is_connected or not self.connection_pool:
            await self.connect()
        
        conn = None
        try:
            self.log_debug("执行PostgreSQL查询", query=query[:200])
            
            # 从连接池获取连接
            conn = self.connection_pool.getconn()
            
            with conn.cursor() as cursor:
                # 执行查询
                if params:
                    cursor.execute(query, params)
                else:
                    cursor.execute(query)
                
                # 获取结果
                if cursor.description:
                    # 有结果集的查询
                    rows = cursor.fetchall()
                    # 转换为字典列表
                    result = [dict(row) for row in rows]
                else:
                    # 没有结果集的查询（如INSERT, UPDATE, DELETE）
                    result = []
                
            # 提交事务
            conn.commit()
            
            self.log_debug(
                "PostgreSQL查询执行完成",
                row_count=len(result)
            )
            
            return result
            
        except Exception as e:
            if conn:
                conn.rollback()
            
            self.log_error("PostgreSQL查询执行失败", error=str(e), query=query[:200])
            raise ConnectionError(f"查询执行失败: {e}")
            
        finally:
            if conn and self.connection_pool:
                self.connection_pool.putconn(conn)
    
    async def close(self) -> None:
        """关闭PostgreSQL连接"""
        try:
            if self.connection_pool:
                self.connection_pool.closeall()
                self.connection_pool = None
            
            self.is_connected = False
            self.log_info("PostgreSQL连接已关闭")
            
        except Exception as e:
            self.log_error("关闭PostgreSQL连接失败", error=str(e))
    
    async def get_table_schema(self, table_name: str) -> Dict[str, Any]:
        """
        获取PostgreSQL表结构信息
        
        Args:
            table_name: 表名
            
        Returns:
            表结构信息
        """
        try:
            query = """
            SELECT 
                column_name,
                data_type,
                is_nullable,
                column_default
            FROM information_schema.columns 
            WHERE table_name = %s
            ORDER BY ordinal_position
            """
            
            result = await self.execute_query(query, {"table_name": table_name})
            
            columns = []
            for row in result:
                columns.append({
                    "name": row["column_name"],
                    "type": row["data_type"],
                    "nullable": row["is_nullable"] == "YES",
                    "default": row["column_default"]
                })
            
            return {
                "table_name": table_name,
                "columns": columns
            }
            
        except Exception as e:
            self.log_error(f"获取PostgreSQL表 {table_name} 结构失败", error=str(e))
            raise ConnectionError(f"获取表结构失败: {e}")
    
    async def get_available_tables(self) -> List[str]:
        """
        获取PostgreSQL可用表列表
        
        Returns:
            表名列表
        """
        try:
            query = """
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'public' 
            AND table_type = 'BASE TABLE'
            ORDER BY table_name
            """
            
            result = await self.execute_query(query)
            tables = [row["table_name"] for row in result]
            
            self.log_info(f"获取到 {len(tables)} 个PostgreSQL表")
            return tables
            
        except Exception as e:
            self.log_error("获取PostgreSQL表列表失败", error=str(e))
            raise ConnectionError(f"获取表列表失败: {e}")
    
    def _optimize_query_for_postgres(self, query: str) -> str:
        """
        为PostgreSQL优化查询
        
        Args:
            query: 原始查询
            
        Returns:
            优化后的查询
        """
        # 这里可以添加PostgreSQL特定的查询优化逻辑
        # 比如：
        # - 使用EXPLAIN分析查询计划
        # - 添加合适的索引提示
        # - 优化JOIN顺序
        
        return query
    
    def _handle_postgres_error(self, error: Exception) -> None:
        """
        处理PostgreSQL特定错误
        
        Args:
            error: 错误信息
        """
        error_msg = str(error)
        
        # 连接错误
        if "connection" in error_msg.lower():
            self.is_connected = False
            self.log_error("PostgreSQL连接断开")
        
        # 语法错误
        elif "syntax error" in error_msg.lower():
            self.log_error("PostgreSQL SQL语法错误", error=error_msg)
        
        # 权限错误
        elif "permission denied" in error_msg.lower():
            self.log_error("PostgreSQL权限不足", error=error_msg)
        
        # 其他错误
        else:
            self.log_error("PostgreSQL未知错误", error=error_msg)
    
    def _create_connection_string(self) -> str:
        """
        创建PostgreSQL连接字符串
        
        Returns:
            连接字符串
        """
        config = self.connection_config
        return (
            f"host={config['host']} "
            f"port={config['port']} "
            f"dbname={config['database']} "
            f"user={config['user']} "
            f"password={config['password']}"
        )

================
File: uqm-backend/src/connectors/sqlite.py
================
"""
SQLite数据库连接器
实现SQLite数据库的连接和查询功能
"""

import sqlite3
import asyncio
from pathlib import Path
from typing import Any, Dict, List, Optional
from urllib.parse import urlparse

from src.connectors.base import BaseConnector
from src.utils.exceptions import ConnectionError


class SQLiteConnector(BaseConnector):
    """SQLite连接器实现"""
    
    def __init__(self, connection_url: str):
        """
        初始化SQLite连接器
        
        Args:
            connection_url: SQLite连接URL (如: sqlite:///path/to/db.sqlite)
        """
        # 解析连接URL
        parsed_url = urlparse(connection_url)
        database_path = parsed_url.path
        
        # 处理相对路径
        if database_path.startswith('/'):
            database_path = database_path[1:]  # 移除开头的 /
        
        connection_config = {
            "database_path": database_path,
            "connection_url": connection_url
        }
        
        super().__init__(connection_config)
        self.connection: Optional[sqlite3.Connection] = None
    
    async def connect(self) -> None:
        """建立SQLite连接"""
        try:
            database_path = self.connection_config["database_path"]
            self.log_info("正在连接SQLite数据库", path=database_path)
            
            # 确保数据库目录存在
            db_file = Path(database_path)
            db_file.parent.mkdir(parents=True, exist_ok=True)
            
            # 创建SQLite连接
            self.connection = sqlite3.connect(
                database_path,
                check_same_thread=False,
                timeout=30.0
            )
            
            # 设置行工厂，返回字典格式
            self.connection.row_factory = sqlite3.Row
            
            # 启用外键约束
            self.connection.execute("PRAGMA foreign_keys = ON")
            
            # 设置WAL模式以提高并发性能
            self.connection.execute("PRAGMA journal_mode = WAL")
            
            # 测试连接
            cursor = self.connection.cursor()
            cursor.execute("SELECT sqlite_version()")
            version = cursor.fetchone()
            self.log_info("SQLite连接成功", version=version[0])
            
            self.is_connected = True
            
        except Exception as e:
            self.log_error("SQLite连接失败", error=str(e))
            self._handle_connection_error(e)
    
    async def execute_query(self, query: str, params: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """
        执行SQLite查询
        
        Args:
            query: SQL查询语句
            params: 查询参数
            
        Returns:
            查询结果
        """
        if not self.is_connected or not self.connection:
            await self.connect()
        
        try:
            self.log_debug("执行SQLite查询", query=query[:200])
            
            cursor = self.connection.cursor()
            
            # 执行查询
            if params:
                # 处理参数格式
                if isinstance(params, dict):
                    # 命名参数
                    cursor.execute(query, params)
                else:
                    # 位置参数
                    cursor.execute(query, params)
            else:
                cursor.execute(query)
            
            # 获取结果
            if cursor.description:
                # 有结果集的查询
                rows = cursor.fetchall()
                # 转换为字典列表
                result = [dict(row) for row in rows]
            else:
                # 没有结果集的查询
                result = []
            
            # 提交事务
            self.connection.commit()
            
            self.log_debug(
                "SQLite查询执行完成",
                row_count=len(result)
            )
            
            return result
            
        except Exception as e:
            if self.connection:
                self.connection.rollback()
            
            self.log_error("SQLite查询执行失败", error=str(e), query=query[:200])
            self._handle_sqlite_error(e)
            raise ConnectionError(f"查询执行失败: {e}")
    
    async def close(self) -> None:
        """关闭SQLite连接"""
        try:
            if self.connection:
                self.connection.close()
                self.connection = None
            
            self.is_connected = False
            self.log_info("SQLite连接已关闭")
            
        except Exception as e:
            self.log_error("关闭SQLite连接失败", error=str(e))
    
    async def get_table_schema(self, table_name: str) -> Dict[str, Any]:
        """
        获取SQLite表结构信息
        
        Args:
            table_name: 表名
            
        Returns:
            表结构信息
        """
        try:
            query = f"PRAGMA table_info({table_name})"
            result = await self.execute_query(query)
            
            columns = []
            for row in result:
                columns.append({
                    "name": row["name"],
                    "type": row["type"],
                    "nullable": row["notnull"] == 0,
                    "default": row["dflt_value"],
                    "primary_key": row["pk"] == 1
                })
            
            return {
                "table_name": table_name,
                "columns": columns
            }
            
        except Exception as e:
            self.log_error(f"获取SQLite表 {table_name} 结构失败", error=str(e))
            raise ConnectionError(f"获取表结构失败: {e}")
    
    async def get_available_tables(self) -> List[str]:
        """
        获取SQLite可用表列表
        
        Returns:
            表名列表
        """
        try:
            query = """
            SELECT name 
            FROM sqlite_master 
            WHERE type='table' 
            AND name NOT LIKE 'sqlite_%'
            ORDER BY name
            """
            
            result = await self.execute_query(query)
            tables = [row["name"] for row in result]
            
            self.log_info(f"获取到 {len(tables)} 个SQLite表")
            return tables
            
        except Exception as e:
            self.log_error("获取SQLite表列表失败", error=str(e))
            raise ConnectionError(f"获取表列表失败: {e}")
    
    async def get_indexes(self, table_name: str) -> List[Dict[str, Any]]:
        """
        获取表的索引信息
        
        Args:
            table_name: 表名
            
        Returns:
            索引信息列表
        """
        try:
            query = f"PRAGMA index_list({table_name})"
            result = await self.execute_query(query)
            
            indexes = []
            for row in result:
                # 获取索引详细信息
                index_name = row["name"]
                index_query = f"PRAGMA index_info({index_name})"
                index_info = await self.execute_query(index_query)
                
                columns = [info["name"] for info in index_info]
                
                indexes.append({
                    "name": index_name,
                    "unique": row["unique"] == 1,
                    "columns": columns
                })
            
            return indexes
            
        except Exception as e:
            self.log_error(f"获取SQLite表 {table_name} 索引失败", error=str(e))
            return []
    
    def _optimize_query_for_sqlite(self, query: str) -> str:
        """
        为SQLite优化查询
        
        Args:
            query: 原始查询
            
        Returns:
            优化后的查询
        """
        # SQLite特定的查询优化
        # 比如：
        # - 使用INDEXED BY提示
        # - 优化复杂的JOIN查询
        # - 使用SQLite特定的函数
        
        return query
    
    def _handle_sqlite_error(self, error: Exception) -> None:
        """
        处理SQLite特定错误
        
        Args:
            error: 错误信息
        """
        error_msg = str(error)
        
        # 数据库锁定
        if "database is locked" in error_msg.lower():
            self.log_error("SQLite数据库被锁定")
        
        # 语法错误
        elif "syntax error" in error_msg.lower():
            self.log_error("SQLite SQL语法错误", error=error_msg)
        
        # 表不存在
        elif "no such table" in error_msg.lower():
            self.log_error("SQLite表不存在", error=error_msg)
        
        # 磁盘空间不足
        elif "disk" in error_msg.lower():
            self.log_error("SQLite磁盘空间不足", error=error_msg)
        
        # 其他错误
        else:
            self.log_error("SQLite未知错误", error=error_msg)
    
    async def vacuum(self) -> None:
        """
        执行VACUUM操作以优化数据库
        """
        try:
            self.log_info("开始执行SQLite VACUUM操作")
            await self.execute_query("VACUUM")
            self.log_info("SQLite VACUUM操作完成")
            
        except Exception as e:
            self.log_error("SQLite VACUUM操作失败", error=str(e))
    
    async def analyze(self) -> None:
        """
        执行ANALYZE操作以更新统计信息
        """
        try:
            self.log_info("开始执行SQLite ANALYZE操作")
            await self.execute_query("ANALYZE")
            self.log_info("SQLite ANALYZE操作完成")
            
        except Exception as e:
            self.log_error("SQLite ANALYZE操作失败", error=str(e))

================
File: uqm-backend/src/core/cache.py
================
"""
查询结果缓存管理模块
支持内存缓存和Redis缓存
"""

import json
import pickle
import time
from abc import ABC, abstractmethod
from typing import Any, Dict, Optional, Union
from datetime import datetime, timedelta
from functools import lru_cache

import redis
from src.config.settings import get_settings
from src.utils.logging import LoggerMixin
from src.utils.exceptions import CacheError


class BaseCacheManager(ABC, LoggerMixin):
    """缓存管理器基类"""
    
    @abstractmethod
    async def get(self, key: str) -> Optional[Any]:
        """获取缓存数据"""
        pass
    
    @abstractmethod
    async def set(self, key: str, value: Any, ttl: int = None) -> bool:
        """设置缓存数据"""
        pass
    
    @abstractmethod
    async def delete(self, key: str) -> bool:
        """删除缓存数据"""
        pass
    
    @abstractmethod
    async def exists(self, key: str) -> bool:
        """检查缓存是否存在"""
        pass
    
    @abstractmethod
    async def clear(self) -> bool:
        """清空所有缓存"""
        pass
    
    @abstractmethod
    async def stats(self) -> Dict[str, Any]:
        """获取缓存统计信息"""
        pass


class MemoryCacheManager(BaseCacheManager):
    """内存缓存管理器"""
    
    def __init__(self, max_size: int = 1000, default_ttl: int = 3600):
        """
        初始化内存缓存管理器
        
        Args:
            max_size: 最大缓存条目数
            default_ttl: 默认TTL(秒)
        """
        self.max_size = max_size
        self.default_ttl = default_ttl
        self.cache: Dict[str, Dict[str, Any]] = {}
        self.access_times: Dict[str, float] = {}
        self.stats_data = {
            "hits": 0,
            "misses": 0,
            "sets": 0,
            "deletes": 0,
            "evictions": 0
        }
    
    async def initialize(self) -> None:
        """初始化缓存管理器"""
        self.log_info("内存缓存管理器初始化完成", max_size=self.max_size)
    
    async def close(self) -> None:
        """关闭缓存管理器"""
        await self.clear()
        self.log_info("内存缓存管理器已关闭")
    
    async def get(self, key: str) -> Optional[Any]:
        """获取缓存数据"""
        try:
            if key not in self.cache:
                self.stats_data["misses"] += 1
                return None
            
            cache_item = self.cache[key]
            
            # 检查是否过期
            if self._is_expired(cache_item):
                await self.delete(key)
                self.stats_data["misses"] += 1
                return None
            
            # 更新访问时间
            self.access_times[key] = time.time()
            self.stats_data["hits"] += 1
            
            # 反序列化数据
            return self._deserialize_data(cache_item["data"])
            
        except Exception as e:
            self.log_error("获取缓存数据失败", key=key, error=str(e))
            raise CacheError(f"获取缓存数据失败: {e}")
    
    async def set(self, key: str, value: Any, ttl: int = None) -> bool:
        """设置缓存数据"""
        try:
            # 如果缓存已满，清理过期项或移除最久未访问的项
            if len(self.cache) >= self.max_size and key not in self.cache:
                await self._cleanup_expired()
                
                if len(self.cache) >= self.max_size:
                    await self._remove_oldest()
            
            # 序列化数据
            serialized_data = self._serialize_data(value)
            
            # 设置缓存项
            expire_time = time.time() + (ttl or self.default_ttl)
            self.cache[key] = {
                "data": serialized_data,
                "expire_time": expire_time,
                "created_time": time.time()
            }
            
            self.access_times[key] = time.time()
            self.stats_data["sets"] += 1
            
            return True
            
        except Exception as e:
            self.log_error("设置缓存数据失败", key=key, error=str(e))
            raise CacheError(f"设置缓存数据失败: {e}")
    
    async def delete(self, key: str) -> bool:
        """删除缓存数据"""
        try:
            if key in self.cache:
                del self.cache[key]
                if key in self.access_times:
                    del self.access_times[key]
                self.stats_data["deletes"] += 1
                return True
            return False
            
        except Exception as e:
            self.log_error("删除缓存数据失败", key=key, error=str(e))
            raise CacheError(f"删除缓存数据失败: {e}")
    
    async def exists(self, key: str) -> bool:
        """检查缓存是否存在"""
        if key not in self.cache:
            return False
        
        cache_item = self.cache[key]
        if self._is_expired(cache_item):
            await self.delete(key)
            return False
        
        return True
    
    async def clear(self) -> bool:
        """清空所有缓存"""
        try:
            self.cache.clear()
            self.access_times.clear()
            self.log_info("内存缓存已清空")
            return True
            
        except Exception as e:
            self.log_error("清空缓存失败", error=str(e))
            raise CacheError(f"清空缓存失败: {e}")
    
    async def stats(self) -> Dict[str, Any]:
        """获取缓存统计信息"""
        total_requests = self.stats_data["hits"] + self.stats_data["misses"]
        hit_rate = self.stats_data["hits"] / total_requests if total_requests > 0 else 0
        
        return {
            "type": "memory",
            "total_items": len(self.cache),
            "max_size": self.max_size,
            "hit_rate": hit_rate,
            **self.stats_data
        }
    
    def _is_expired(self, cache_item: Dict[str, Any]) -> bool:
        """检查缓存项是否过期"""
        return time.time() > cache_item["expire_time"]
    
    async def _cleanup_expired(self) -> None:
        """清理过期的缓存项"""
        expired_keys = []
        current_time = time.time()
        
        for key, cache_item in self.cache.items():
            if current_time > cache_item["expire_time"]:
                expired_keys.append(key)
        
        for key in expired_keys:
            await self.delete(key)
        
        if expired_keys:
            self.log_info("清理过期缓存项", count=len(expired_keys))
    
    async def _remove_oldest(self) -> None:
        """移除最久未访问的缓存项"""
        if not self.access_times:
            return
        
        # 找到最久未访问的键
        oldest_key = min(self.access_times.keys(), key=lambda k: self.access_times[k])
        await self.delete(oldest_key)
        self.stats_data["evictions"] += 1
        
        self.log_info("移除最久未访问的缓存项", key=oldest_key)
    
    def _serialize_data(self, data: Any) -> bytes:
        """序列化缓存数据"""
        try:
            return pickle.dumps(data)
        except Exception as e:
            self.log_error("序列化数据失败", error=str(e))
            raise CacheError(f"序列化数据失败: {e}")
    
    def _deserialize_data(self, data: bytes) -> Any:
        """反序列化缓存数据"""
        try:
            return pickle.loads(data)
        except Exception as e:
            self.log_error("反序列化数据失败", error=str(e))
            raise CacheError(f"反序列化数据失败: {e}")


class RedisCacheManager(BaseCacheManager):
    """Redis缓存管理器"""
    
    def __init__(self, redis_url: str, default_ttl: int = 3600):
        """
        初始化Redis缓存管理器
        
        Args:
            redis_url: Redis连接URL
            default_ttl: 默认TTL(秒)
        """
        self.redis_url = redis_url
        self.default_ttl = default_ttl
        self.redis_client: Optional[redis.Redis] = None
        self.stats_data = {
            "hits": 0,
            "misses": 0,
            "sets": 0,
            "deletes": 0
        }
    
    async def initialize(self) -> None:
        """初始化Redis连接"""
        try:
            self.redis_client = redis.from_url(
                self.redis_url,
                decode_responses=False,
                socket_timeout=5,
                socket_connect_timeout=5,
                retry_on_timeout=True
            )
            
            # 测试连接
            await self._ping()
            
            self.log_info("Redis缓存管理器初始化完成", redis_url=self.redis_url)
            
        except Exception as e:
            self.log_error("Redis缓存管理器初始化失败", error=str(e))
            raise CacheError(f"Redis缓存管理器初始化失败: {e}")
    
    async def close(self) -> None:
        """关闭Redis连接"""
        if self.redis_client:
            await self.redis_client.close()
            self.log_info("Redis缓存管理器已关闭")
    
    async def get(self, key: str) -> Optional[Any]:
        """获取缓存数据"""
        try:
            if not self.redis_client:
                raise CacheError("Redis客户端未初始化")
            
            data = self.redis_client.get(key)
            
            if data is None:
                self.stats_data["misses"] += 1
                return None
            
            self.stats_data["hits"] += 1
            return self._deserialize_data(data)
            
        except Exception as e:
            self.log_error("获取Redis缓存数据失败", key=key, error=str(e))
            raise CacheError(f"获取Redis缓存数据失败: {e}")
    
    async def set(self, key: str, value: Any, ttl: int = None) -> bool:
        """设置缓存数据"""
        try:
            if not self.redis_client:
                raise CacheError("Redis客户端未初始化")
            
            serialized_data = self._serialize_data(value)
            
            success = self.redis_client.setex(
                key, 
                ttl or self.default_ttl, 
                serialized_data
            )
            
            if success:
                self.stats_data["sets"] += 1
            
            return bool(success)
            
        except Exception as e:
            self.log_error("设置Redis缓存数据失败", key=key, error=str(e))
            raise CacheError(f"设置Redis缓存数据失败: {e}")
    
    async def delete(self, key: str) -> bool:
        """删除缓存数据"""
        try:
            if not self.redis_client:
                raise CacheError("Redis客户端未初始化")
            
            result = self.redis_client.delete(key)
            
            if result > 0:
                self.stats_data["deletes"] += 1
                return True
            
            return False
            
        except Exception as e:
            self.log_error("删除Redis缓存数据失败", key=key, error=str(e))
            raise CacheError(f"删除Redis缓存数据失败: {e}")
    
    async def exists(self, key: str) -> bool:
        """检查缓存是否存在"""
        try:
            if not self.redis_client:
                raise CacheError("Redis客户端未初始化")
            
            return bool(self.redis_client.exists(key))
            
        except Exception as e:
            self.log_error("检查Redis缓存存在性失败", key=key, error=str(e))
            raise CacheError(f"检查Redis缓存存在性失败: {e}")
    
    async def clear(self) -> bool:
        """清空所有缓存"""
        try:
            if not self.redis_client:
                raise CacheError("Redis客户端未初始化")
            
            # 注意：这将清空整个Redis数据库，生产环境需要谨慎使用
            self.redis_client.flushdb()
            self.log_info("Redis缓存已清空")
            return True
            
        except Exception as e:
            self.log_error("清空Redis缓存失败", error=str(e))
            raise CacheError(f"清空Redis缓存失败: {e}")
    
    async def stats(self) -> Dict[str, Any]:
        """获取缓存统计信息"""
        try:
            if not self.redis_client:
                raise CacheError("Redis客户端未初始化")
            
            info = self.redis_client.info()
            total_requests = self.stats_data["hits"] + self.stats_data["misses"]
            hit_rate = self.stats_data["hits"] / total_requests if total_requests > 0 else 0
            
            return {
                "type": "redis",
                "connected_clients": info.get("connected_clients", 0),
                "used_memory": info.get("used_memory", 0),
                "used_memory_human": info.get("used_memory_human", "0B"),
                "hit_rate": hit_rate,
                **self.stats_data
            }
            
        except Exception as e:
            self.log_error("获取Redis统计信息失败", error=str(e))
            return {
                "type": "redis",
                "error": str(e),
                **self.stats_data
            }
    
    async def _ping(self) -> None:
        """测试Redis连接"""
        if not self.redis_client:
            raise CacheError("Redis客户端未初始化")
        
        result = self.redis_client.ping()
        if not result:
            raise CacheError("Redis连接测试失败")
    
    def _serialize_data(self, data: Any) -> bytes:
        """序列化缓存数据"""
        try:
            return pickle.dumps(data)
        except Exception as e:
            self.log_error("序列化数据失败", error=str(e))
            raise CacheError(f"序列化数据失败: {e}")
    
    def _deserialize_data(self, data: bytes) -> Any:
        """反序列化缓存数据"""
        try:
            return pickle.loads(data)
        except Exception as e:
            self.log_error("反序列化数据失败", error=str(e))
            raise CacheError(f"反序列化数据失败: {e}")


# 全局缓存管理器实例
_cache_manager: Optional[BaseCacheManager] = None


@lru_cache()
def get_cache_manager() -> BaseCacheManager:
    """获取缓存管理器实例(单例模式)"""
    global _cache_manager
    
    if _cache_manager is None:
        settings = get_settings()
        cache_config = settings.get_cache_config()
        
        if cache_config["type"].lower() == "redis":
            _cache_manager = RedisCacheManager(
                redis_url=cache_config["redis_url"],
                default_ttl=cache_config["default_timeout"]
            )
        else:
            _cache_manager = MemoryCacheManager(
                max_size=cache_config["max_size"],
                default_ttl=cache_config["default_timeout"]
            )
    
    return _cache_manager

================
File: uqm-backend/src/core/engine.py
================
"""
UQM执行引擎主类
负责协调整个查询执行流程
"""

import time
import hashlib
from typing import Any, Dict, List, Optional
from functools import lru_cache

from src.api.models import UQMResponse, StepResult, Metadata, StepType
from src.core.parser import UQMParser
from src.core.executor import Executor
from src.core.cache import get_cache_manager
from src.connectors.base import get_connector_manager
from src.utils.logging import LoggerMixin
from src.utils.exceptions import ValidationError, ExecutionError
from src.config.settings import get_settings


class UQMEngine(LoggerMixin):
    """UQM执行引擎主类"""
    
    def __init__(self):
        """初始化UQM执行引擎"""
        self.parser = UQMParser()
        self.cache_manager = get_cache_manager()
        self.connector_manager = get_connector_manager()
        self.settings = get_settings()
    
    async def process(self, uqm_data: Dict[str, Any], 
                     parameters: Optional[Dict[str, Any]] = None,
                     options: Optional[Dict[str, Any]] = None) -> UQMResponse:
        """
        处理UQM查询的主入口方法
        
        Args:
            uqm_data: UQM JSON数据
            parameters: 查询参数
            options: 执行选项
            
        Returns:
            查询执行结果
            
        Raises:
            ValidationError: 验证失败
            ExecutionError: 执行失败
        """
        start_time = time.time()
        
        try:
            self.log_info(
                "开始处理UQM查询",
                uqm_name=uqm_data.get("metadata", {}).get("name", "未命名")
            )
            
            # 参数预处理
            parameters = parameters or {}
            options = options or {}
            
            # 解析UQM数据
            parsed_data = self.parser.parse(uqm_data)
            
            # 参数替换
            processed_data = self._substitute_parameters(parsed_data, parameters)
            
            # 生成缓存键
            cache_key = self._generate_cache_key(processed_data, parameters)
            
            # 检查缓存
            cached_result = None
            if options.get("cache_enabled", True):
                cached_result = await self.cache_manager.get(cache_key)
                if cached_result:
                    self.log_info("命中缓存", cache_key=cache_key)
                    return cached_result
            
            # 创建执行器并执行
            executor = Executor(
                steps=processed_data["steps"],
                connector_manager=self.connector_manager,
                cache_manager=self.cache_manager,
                options=options
            )
            
            execution_result = await executor.execute()
            
            # 获取输出步骤的结果
            output_step = processed_data["output"]
            output_data = execution_result.get_step_data(output_step)
            
            # 构建响应
            execution_time = time.time() - start_time
            response = UQMResponse(
                success=True,
                data=output_data,
                metadata=Metadata(**processed_data["metadata"]),
                execution_info={
                    "total_time": execution_time,
                    "row_count": len(output_data) if output_data else 0,
                    "cache_hit": False,
                    "steps_executed": len(processed_data["steps"])
                },
                step_results=self._build_step_results(execution_result.step_results)
            )
            
            # 缓存结果
            if options.get("cache_enabled", True):
                cache_ttl = options.get("cache_ttl", self.settings.CACHE_DEFAULT_TIMEOUT)
                await self.cache_manager.set(cache_key, response, cache_ttl)
            
            self.log_info(
                "UQM查询处理完成",
                execution_time=execution_time,
                row_count=len(output_data) if output_data else 0
            )
            
            return response
            
        except ValidationError as e:
            self.log_error("UQM查询验证失败", error=str(e))
            raise
            
        except ExecutionError as e:
            self.log_error("UQM查询执行失败", error=str(e))
            raise
            
        except Exception as e:
            execution_time = time.time() - start_time
            self.log_error(
                "UQM查询处理出现未知错误",
                error=str(e),
                execution_time=execution_time,
                exc_info=True
            )
            raise ExecutionError(f"查询处理失败: {e}")
    
    async def validate_query(self, uqm_data: Dict[str, Any]) -> Any:
        """
        验证UQM查询有效性
        
        Args:
            uqm_data: UQM JSON数据
            
        Returns:
            验证结果
        """
        try:
            self.log_info("开始验证UQM查询")
            
            # 使用解析器进行验证
            validation_result = self.parser.validate_schema(uqm_data)
            
            self.log_info(
                "UQM查询验证完成",
                valid=validation_result.valid,
                error_count=len(validation_result.errors) if validation_result.errors else 0
            )
            
            return validation_result
            
        except Exception as e:
            self.log_error("UQM查询验证出现错误", error=str(e))
            raise ValidationError(f"查询验证失败: {e}")
    
    def _substitute_parameters(self, uqm_data: Dict[str, Any], 
                             parameters: Dict[str, Any]) -> Dict[str, Any]:
        """
        参数替换处理
        
        Args:
            uqm_data: 解析后的UQM数据
            parameters: 参数值字典
            
        Returns:
            参数替换后的UQM数据
        """
        try:
            self.log_info("开始参数替换", parameter_count=len(parameters))
            
            # 深拷贝数据以避免修改原始数据
            import copy
            processed_data = copy.deepcopy(uqm_data)
            
            # 将数据转换为JSON字符串进行参数替换
            import json
            data_str = json.dumps(processed_data)
            
            # 替换参数
            for param_name, param_value in parameters.items():
                placeholder = f"${param_name}"
                # 如果参数值是字符串，需要添加引号
                if isinstance(param_value, str):
                    replacement = json.dumps(param_value)
                else:
                    replacement = json.dumps(param_value)
                
                data_str = data_str.replace(f'"{placeholder}"', replacement)
                data_str = data_str.replace(placeholder, replacement)
            
            # 转换回字典
            processed_data = json.loads(data_str)
            
            self.log_info("参数替换完成")
            return processed_data
            
        except Exception as e:
            self.log_error("参数替换失败", error=str(e))
            raise ValidationError(f"参数替换失败: {e}")
    
    def _generate_cache_key(self, uqm_data: Dict[str, Any], 
                           parameters: Dict[str, Any]) -> str:
        """
        生成缓存键
        
        Args:
            uqm_data: UQM数据
            parameters: 参数
            
        Returns:
            缓存键
        """
        try:
            # 创建包含UQM数据和参数的字典
            cache_data = {
                "uqm": uqm_data,
                "parameters": parameters
            }
            
            # 序列化并生成hash
            import json
            data_str = json.dumps(cache_data, sort_keys=True)
            cache_key = hashlib.md5(data_str.encode('utf-8')).hexdigest()
            
            return f"uqm_cache:{cache_key}"
            
        except Exception as e:
            self.log_error("生成缓存键失败", error=str(e))
            # 如果生成缓存键失败，返回一个基于时间的键（不会命中缓存）
            return f"uqm_cache:no_cache_{int(time.time())}"
    
    def _build_step_results(self, step_results: Dict[str, Any]) -> List[StepResult]:
        """
        构建步骤结果列表
        
        Args:
            step_results: 执行器返回的步骤结果
            
        Returns:
            步骤结果列表
        """
        results = []
        
        for step_name, step_data in step_results.items():
            result = StepResult(
                step_name=step_name,
                step_type=StepType(step_data.get("type", "query")),
                status=step_data.get("status", "completed"),
                data=step_data.get("data"),
                row_count=step_data.get("row_count", 0),
                execution_time=step_data.get("execution_time", 0.0),
                cache_hit=step_data.get("cache_hit", False),
                error=step_data.get("error")
            )
            results.append(result)
        
        return results


# 全局引擎实例
_uqm_engine: Optional[UQMEngine] = None


@lru_cache()
def get_uqm_engine() -> UQMEngine:
    """获取UQM引擎实例(单例模式)"""
    global _uqm_engine
    
    if _uqm_engine is None:
        _uqm_engine = UQMEngine()
    
    return _uqm_engine

================
File: uqm-backend/src/core/executor.py
================
"""
步骤执行器模块
负责按顺序执行UQM定义的各个步骤
"""

import time
import hashlib
from typing import Any, Dict, List, Optional, Union
from dataclasses import dataclass

from src.steps.query_step import QueryStep
from src.steps.enrich_step import EnrichStep
from src.steps.pivot_step import PivotStep
from src.steps.unpivot_step import UnpivotStep
from src.steps.union_step import UnionStep
from src.steps.assert_step import AssertStep
from src.core.cache import BaseCacheManager
from src.connectors.base import BaseConnectorManager
from src.utils.logging import LoggerMixin
from src.utils.exceptions import ExecutionError


@dataclass
class ExecutionResult:
    """执行结果数据类"""
    step_results: Dict[str, Any]
    step_data: Dict[str, List[Dict[str, Any]]]
    
    def get_step_data(self, step_name: str) -> Optional[List[Dict[str, Any]]]:
        """获取指定步骤的数据"""
        return self.step_data.get(step_name)


class Executor(LoggerMixin):
    """步骤执行管理器"""
    
    def __init__(self, steps: List[Dict[str, Any]], 
                 connector_manager: BaseConnectorManager,
                 cache_manager: BaseCacheManager,
                 options: Optional[Dict[str, Any]] = None):
        """
        初始化执行器
        
        Args:
            steps: 步骤列表
            connector_manager: 连接器管理器
            cache_manager: 缓存管理器
            options: 执行选项
        """
        self.steps = steps
        self.connector_manager = connector_manager
        self.cache_manager = cache_manager
        self.options = options or {}
        
        # 步骤执行结果存储
        self.step_results: Dict[str, Any] = {}
        self.step_data: Dict[str, List[Dict[str, Any]]] = {}
        
        # 步骤类型映射
        self.step_classes = {
            "query": QueryStep,
            "enrich": EnrichStep,
            "pivot": PivotStep,
            "unpivot": UnpivotStep,
            "union": UnionStep,
            "assert": AssertStep
        }
    
    async def execute(self) -> ExecutionResult:
        """
        执行所有步骤
        
        Returns:
            执行结果
            
        Raises:
            ExecutionError: 执行失败
        """
        try:
            self.log_info("开始执行步骤", step_count=len(self.steps))
            
            for step_config in self.steps:
                step_name = step_config["name"]
                
                try:
                    # 执行单个步骤
                    await self._execute_step(step_config)
                    
                    self.log_info(f"步骤 {step_name} 执行完成")
                    
                except Exception as e:
                    self.log_error(f"步骤 {step_name} 执行失败", error=str(e))
                    
                    # 记录步骤执行失败
                    self.step_results[step_name] = {
                        "type": step_config["type"],
                        "status": "failed",
                        "error": str(e),
                        "execution_time": 0.0,
                        "row_count": 0,
                        "cache_hit": False
                    }
                    
                    # 根据选项决定是否继续执行
                    if not self.options.get("continue_on_error", False):
                        raise ExecutionError(f"步骤 {step_name} 执行失败: {e}")
            
            self.log_info("所有步骤执行完成")
            
            return ExecutionResult(
                step_results=self.step_results,
                step_data=self.step_data
            )
            
        except ExecutionError:
            raise
        except Exception as e:
            self.log_error("步骤执行过程出现未知错误", error=str(e), exc_info=True)
            raise ExecutionError(f"步骤执行失败: {e}")
    
    async def _execute_step(self, step_config: Dict[str, Any]) -> None:
        """
        执行单个步骤
        
        Args:
            step_config: 步骤配置
        """
        step_name = step_config["name"]
        step_type = step_config["type"]
        config = step_config["config"]
        
        start_time = time.time()
        
        try:
            self.log_info(f"开始执行步骤: {step_name} (类型: {step_type})")
            
            # 检查缓存
            cache_key = self._generate_cache_key(step_config)
            cached_data = None
            cache_hit = False
            
            if self.options.get("cache_enabled", True):
                cached_data = await self.cache_manager.get(cache_key)
                if cached_data is not None:
                    cache_hit = True
                    self.log_info(f"步骤 {step_name} 命中缓存")
            
            if cache_hit:
                # 使用缓存数据
                step_data = cached_data
            else:
                # 执行步骤
                step_data = await self._execute_step_by_type(step_type, config)
                
                # 缓存结果
                if self.options.get("cache_enabled", True) and step_data:
                    cache_ttl = self._parse_ttl(config.get("cache_ttl", "1h"))
                    await self.cache_manager.set(cache_key, step_data, cache_ttl)
            
            execution_time = time.time() - start_time
            
            # 记录步骤执行结果
            self.step_results[step_name] = {
                "type": step_type,
                "status": "completed",
                "execution_time": execution_time,
                "row_count": len(step_data) if step_data else 0,
                "cache_hit": cache_hit
            }
            
            # 存储步骤数据
            self.step_data[step_name] = step_data or []
            
            self.log_info(
                f"步骤 {step_name} 执行完成",
                execution_time=execution_time,
                row_count=len(step_data) if step_data else 0,
                cache_hit=cache_hit
            )
            
        except Exception as e:
            execution_time = time.time() - start_time
            self.log_error(
                f"步骤 {step_name} 执行失败",
                error=str(e),
                execution_time=execution_time
            )
            raise ExecutionError(f"步骤 {step_name} 执行失败: {e}")
    
    async def _execute_step_by_type(self, step_type: str, 
                                   config: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        根据步骤类型执行步骤
        
        Args:
            step_type: 步骤类型
            config: 步骤配置
            
        Returns:
            步骤执行结果数据
        """
        if step_type not in self.step_classes:
            raise ExecutionError(f"不支持的步骤类型: {step_type}")
        
        # 获取步骤类
        step_class = self.step_classes[step_type]
        
        # 创建步骤实例
        step_instance = step_class(config)
        
        # 准备执行上下文
        context = self._prepare_execution_context(config)
        
        # 执行步骤
        result = await step_instance.execute(context)
        
        return result
    
    def _prepare_execution_context(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        准备步骤执行上下文
        
        Args:
            config: 步骤配置
            
        Returns:
            执行上下文
        """
        context = {
            "connector_manager": self.connector_manager,
            "cache_manager": self.cache_manager,
            "options": self.options,
            "step_data": self.step_data,
            "get_source_data": self._get_source_data
        }
        
        return context
    
    def _get_source_data(self, source_name: Union[str, List[str]]) -> Union[List[Dict[str, Any]], Dict[str, List[Dict[str, Any]]]]:
        """
        获取源步骤数据
        
        Args:
            source_name: 源步骤名称或名称列表
            
        Returns:
            源步骤数据
        """
        if isinstance(source_name, str):
            if source_name not in self.step_data:
                raise ExecutionError(f"源步骤数据不存在: {source_name}")
            return self.step_data[source_name]
        
        elif isinstance(source_name, list):
            result = {}
            for name in source_name:
                if name not in self.step_data:
                    raise ExecutionError(f"源步骤数据不存在: {name}")
                result[name] = self.step_data[name]
            return result
        
        else:
            raise ExecutionError(f"无效的源步骤名称类型: {type(source_name)}")
    
    def _generate_cache_key(self, step_config: Dict[str, Any]) -> str:
        """
        生成步骤缓存键
        
        Args:
            step_config: 步骤配置
            
        Returns:
            缓存键
        """
        try:
            # 创建包含步骤配置和依赖数据的字典
            cache_data = {
                "step_config": step_config,
                "dependency_data": {}
            }
            
            # 添加依赖步骤的数据hash
            config = step_config.get("config", {})
            if "source" in config:
                source = config["source"]
                if isinstance(source, str):
                    cache_data["dependency_data"][source] = self._get_data_hash(source)
                elif isinstance(source, list):
                    for src in source:
                        cache_data["dependency_data"][src] = self._get_data_hash(src)
            
            if "sources" in config:
                sources = config["sources"]
                if isinstance(sources, list):
                    for src in sources:
                        cache_data["dependency_data"][src] = self._get_data_hash(src)
            
            # 序列化并生成hash
            import json
            data_str = json.dumps(cache_data, sort_keys=True)
            cache_key = hashlib.md5(data_str.encode('utf-8')).hexdigest()
            
            step_name = step_config["name"]
            return f"step_cache:{step_name}:{cache_key}"
            
        except Exception as e:
            self.log_error("生成步骤缓存键失败", error=str(e))
            # 如果生成缓存键失败，返回一个基于时间的键（不会命中缓存）
            step_name = step_config.get("name", "unknown")
            return f"step_cache:{step_name}:no_cache_{int(time.time())}"
    
    def _get_data_hash(self, step_name: str) -> str:
        """
        获取步骤数据的hash值
        
        Args:
            step_name: 步骤名称
            
        Returns:
            数据hash值
        """
        try:
            if step_name not in self.step_data:
                return "no_data"
            
            import json
            data_str = json.dumps(self.step_data[step_name], sort_keys=True)
            return hashlib.md5(data_str.encode('utf-8')).hexdigest()
            
        except Exception:
            return "hash_error"
    
    def _parse_ttl(self, ttl_str: str) -> int:
        """
        解析TTL字符串
        
        Args:
            ttl_str: TTL字符串 (如: "1h", "30m", "3600s")
            
        Returns:
            TTL秒数
        """
        try:
            if isinstance(ttl_str, int):
                return ttl_str
            
            if not isinstance(ttl_str, str):
                return 3600  # 默认1小时
            
            ttl_str = ttl_str.lower().strip()
            
            # 解析时间单位
            if ttl_str.endswith('s'):
                return int(ttl_str[:-1])
            elif ttl_str.endswith('m'):
                return int(ttl_str[:-1]) * 60
            elif ttl_str.endswith('h'):
                return int(ttl_str[:-1]) * 3600
            elif ttl_str.endswith('d'):
                return int(ttl_str[:-1]) * 86400
            else:
                # 假设是秒数
                return int(ttl_str)
                
        except (ValueError, TypeError):
            self.log_warning(f"无法解析TTL字符串: {ttl_str}，使用默认值3600秒")
            return 3600

================
File: uqm-backend/src/core/parser.py
================
"""
UQM JSON解析器模块
负责解析和验证UQM JSON定义
"""

import json
from typing import Any, Dict, List, Optional, Set, Tuple
from pathlib import Path

import jsonschema
from jsonschema import validate, ValidationError as JsonSchemaValidationError

from src.api.models import ValidationError as UQMValidationError, ValidationResponse
from src.utils.logging import LoggerMixin
from src.utils.exceptions import ParseError, ValidationError


class UQMParser(LoggerMixin):
    """UQM数据解析器"""
    
    def __init__(self, schema_path: Optional[str] = None):
        """
        初始化UQM解析器
        
        Args:
            schema_path: UQM Schema文件路径
        """
        self.schema_path = schema_path
        self.schema = None
        
        if schema_path:
            self.schema = self._load_schema(schema_path)
        else:
            # 使用内置的基础Schema
            self.schema = self._get_default_schema()
    
    def parse(self, uqm_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        解析UQM数据
        
        Args:
            uqm_data: UQM JSON数据
            
        Returns:
            解析后的UQM数据
            
        Raises:
            ParseError: 解析失败
        """
        try:
            self.log_info("开始解析UQM数据")
            
            # 验证基本结构
            self._validate_basic_structure(uqm_data)
            
            # 提取各个组件
            metadata = self.extract_metadata(uqm_data)
            steps = self.extract_steps(uqm_data)
            parameters = self.extract_parameters(uqm_data)
            output_step = self.get_output_step(uqm_data)
            
            # 验证步骤依赖关系
            self._validate_step_dependencies(steps)
            
            # 解析步骤执行顺序
            execution_order = self._resolve_step_order(steps)
            
            parsed_data = {
                "metadata": metadata,
                "steps": steps,
                "parameters": parameters,
                "output": output_step,
                "execution_order": execution_order
            }
            
            self.log_info(
                "UQM数据解析完成",
                step_count=len(steps),
                output_step=output_step
            )
            
            return parsed_data
            
        except Exception as e:
            self.log_error("UQM数据解析失败", error=str(e))
            raise ParseError(f"UQM数据解析失败: {e}")
    
    def extract_steps(self, uqm_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        提取步骤列表
        
        Args:
            uqm_data: UQM数据
            
        Returns:
            步骤列表
        """
        steps = uqm_data.get("steps", [])
        
        if not isinstance(steps, list):
            raise ParseError("steps必须是一个数组")
        
        if not steps:
            raise ParseError("至少需要定义一个步骤")
        
        # 验证每个步骤的基本结构
        for i, step in enumerate(steps):
            if not isinstance(step, dict):
                raise ParseError(f"步骤 {i} 必须是一个对象")
            
            if "name" not in step:
                raise ParseError(f"步骤 {i} 缺少name字段")
            
            if "type" not in step:
                raise ParseError(f"步骤 {step['name']} 缺少type字段")
            
            if "config" not in step:
                raise ParseError(f"步骤 {step['name']} 缺少config字段")
        
        return steps
    
    def get_output_step(self, uqm_data: Dict[str, Any]) -> str:
        """
        获取输出步骤名称
        
        Args:
            uqm_data: UQM数据
            
        Returns:
            输出步骤名称
        """
        output_step = uqm_data.get("output")
        
        if not output_step:
            # 如果没有指定输出步骤，使用最后一个步骤
            steps = uqm_data.get("steps", [])
            if steps:
                output_step = steps[-1]["name"]
            else:
                raise ParseError("无法确定输出步骤")
        
        # 验证输出步骤是否存在
        step_names = {step["name"] for step in uqm_data.get("steps", [])}
        if output_step not in step_names:
            raise ParseError(f"输出步骤 '{output_step}' 不存在")
        
        return output_step
    
    def extract_metadata(self, uqm_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        提取元数据
        
        Args:
            uqm_data: UQM数据
            
        Returns:
            元数据字典
        """
        metadata = uqm_data.get("metadata", {})
        
        if not isinstance(metadata, dict):
            raise ParseError("metadata必须是一个对象")
        
        # 设置默认值
        default_metadata = {
            "name": "未命名查询",
            "description": "",
            "version": "1.0",
            "author": "",
            "tags": []
        }
        
        # 合并默认值和用户提供的元数据
        result = {**default_metadata, **metadata}
        
        return result
    
    def extract_parameters(self, uqm_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        提取参数定义
        
        Args:
            uqm_data: UQM数据
            
        Returns:
            参数定义列表
        """
        parameters = uqm_data.get("parameters", [])
        
        if not isinstance(parameters, list):
            raise ParseError("parameters必须是一个数组")
        
        # 验证每个参数定义
        for i, param in enumerate(parameters):
            if not isinstance(param, dict):
                raise ParseError(f"参数 {i} 必须是一个对象")
            
            if "name" not in param:
                raise ParseError(f"参数 {i} 缺少name字段")
            
            if "type" not in param:
                raise ParseError(f"参数 {param['name']} 缺少type字段")
        
        return parameters
    
    def validate_schema(self, uqm_data: Dict[str, Any]) -> ValidationResponse:
        """
        验证UQM数据是否符合Schema
        
        Args:
            uqm_data: UQM数据
            
        Returns:
            验证结果
        """
        errors = []
        warnings = []
        
        try:
            # 如果有Schema，进行Schema验证
            if self.schema:
                try:
                    validate(instance=uqm_data, schema=self.schema)
                except JsonSchemaValidationError as e:
                    errors.append(UQMValidationError(
                        field=".".join(str(x) for x in e.path),
                        message=e.message,
                        value=e.instance
                    ))
            
            # 进行业务逻辑验证
            try:
                self.parse(uqm_data)
            except ParseError as e:
                errors.append(UQMValidationError(
                    field="general",
                    message=str(e),
                    value=None
                ))
            
            # 检查潜在的警告
            warnings.extend(self._check_warnings(uqm_data))
            
            return ValidationResponse(
                valid=len(errors) == 0,
                errors=errors if errors else None,
                warnings=warnings if warnings else None
            )
            
        except Exception as e:
            self.log_error("UQM验证过程出现错误", error=str(e))
            return ValidationResponse(
                valid=False,
                errors=[UQMValidationError(
                    field="validation",
                    message=f"验证过程出现错误: {e}",
                    value=None
                )]
            )
    
    def _validate_basic_structure(self, uqm_data: Dict[str, Any]) -> None:
        """验证UQM基本结构"""
        if not isinstance(uqm_data, dict):
            raise ParseError("UQM数据必须是一个JSON对象")
        
        required_fields = ["steps"]
        for field in required_fields:
            if field not in uqm_data:
                raise ParseError(f"缺少必需字段: {field}")
    
    def _validate_step_dependencies(self, steps: List[Dict[str, Any]]) -> None:
        """
        验证步骤依赖关系
        
        Args:
            steps: 步骤列表
        """
        step_names = {step["name"] for step in steps}
        
        for step in steps:
            step_name = step["name"]
            step_config = step.get("config", {})
            
            # 检查source引用
            if "source" in step_config:
                source = step_config["source"]
                if isinstance(source, str) and source not in step_names:
                    raise ParseError(f"步骤 '{step_name}' 引用了不存在的源步骤: '{source}'")
                elif isinstance(source, list):
                    for src in source:
                        if src not in step_names:
                            raise ParseError(f"步骤 '{step_name}' 引用了不存在的源步骤: '{src}'")
            
            # 检查sources引用（用于union步骤）
            if "sources" in step_config:
                sources = step_config["sources"]
                if isinstance(sources, list):
                    for src in sources:
                        if src not in step_names:
                            raise ParseError(f"步骤 '{step_name}' 引用了不存在的源步骤: '{src}'")
    
    def _resolve_step_order(self, steps: List[Dict[str, Any]]) -> List[str]:
        """
        解析步骤执行顺序（拓扑排序）
        
        Args:
            steps: 步骤列表
            
        Returns:
            按执行顺序排列的步骤名称列表
        """
        # 构建依赖图
        dependencies = {}
        step_names = set()
        
        for step in steps:
            step_name = step["name"]
            step_names.add(step_name)
            dependencies[step_name] = set()
            
            step_config = step.get("config", {})
            
            # 添加source依赖
            if "source" in step_config:
                source = step_config["source"]
                if isinstance(source, str):
                    dependencies[step_name].add(source)
                elif isinstance(source, list):
                    dependencies[step_name].update(source)
            
            # 添加sources依赖
            if "sources" in step_config:
                sources = step_config["sources"]
                if isinstance(sources, list):
                    dependencies[step_name].update(sources)
        
        # 拓扑排序
        result = []
        visited = set()
        temp_visited = set()
        
        def visit(node: str):
            if node in temp_visited:
                raise ParseError(f"检测到循环依赖，涉及步骤: {node}")
            
            if node not in visited:
                temp_visited.add(node)
                
                for dep in dependencies.get(node, set()):
                    visit(dep)
                
                temp_visited.remove(node)
                visited.add(node)
                result.append(node)
        
        for step_name in step_names:
            if step_name not in visited:
                visit(step_name)
        
        return result
    
    def _check_warnings(self, uqm_data: Dict[str, Any]) -> List[str]:
        """检查潜在的警告问题"""
        warnings = []
        
        # 检查元数据完整性
        metadata = uqm_data.get("metadata", {})
        if not metadata.get("description"):
            warnings.append("建议添加查询描述")
        
        if not metadata.get("author"):
            warnings.append("建议添加作者信息")
        
        # 检查步骤数量
        steps = uqm_data.get("steps", [])
        if len(steps) > 10:
            warnings.append("步骤数量较多，可能影响性能")
        
        # 检查参数使用
        parameters = uqm_data.get("parameters", [])
        if parameters:
            param_names = {param["name"] for param in parameters}
            uqm_str = json.dumps(uqm_data)
            
            for param_name in param_names:
                if f"${param_name}" not in uqm_str:
                    warnings.append(f"参数 '{param_name}' 定义了但未使用")
        
        return warnings
    
    def _load_schema(self, schema_path: str) -> Dict[str, Any]:
        """
        加载UQM Schema文件
        
        Args:
            schema_path: Schema文件路径
            
        Returns:
            Schema字典
        """
        try:
            schema_file = Path(schema_path)
            if not schema_file.exists():
                raise FileNotFoundError(f"Schema文件不存在: {schema_path}")
            
            with open(schema_file, 'r', encoding='utf-8') as f:
                schema = json.load(f)
            
            self.log_info("UQM Schema加载成功", schema_path=schema_path)
            return schema
            
        except Exception as e:
            self.log_error("加载UQM Schema失败", error=str(e))
            raise ParseError(f"加载UQM Schema失败: {e}")
    
    def _get_default_schema(self) -> Dict[str, Any]:
        """获取默认的UQM Schema"""
        return {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "type": "object",
            "required": ["steps"],
            "properties": {
                "metadata": {
                    "type": "object",
                    "properties": {
                        "name": {"type": "string"},
                        "description": {"type": "string"},
                        "version": {"type": "string"},
                        "author": {"type": "string"},
                        "tags": {
                            "type": "array",
                            "items": {"type": "string"}
                        }
                    }
                },
                "parameters": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "required": ["name", "type"],
                        "properties": {
                            "name": {"type": "string"},
                            "type": {"type": "string"},
                            "default": {},
                            "required": {"type": "boolean"},
                            "description": {"type": "string"}
                        }
                    }
                },
                "steps": {
                    "type": "array",
                    "minItems": 1,
                    "items": {
                        "type": "object",
                        "required": ["name", "type", "config"],
                        "properties": {
                            "name": {"type": "string"},
                            "type": {
                                "type": "string",
                                "enum": ["query", "enrich", "pivot", "unpivot", "union", "assert"]
                            },
                            "config": {"type": "object"}
                        }
                    }
                },
                "output": {"type": "string"}
            }
        }

================
File: uqm-backend/src/main.py
================
"""
UQM Backend 主程序入口
负责启动FastAPI应用程序和配置相关服务
"""

import uvicorn
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from contextlib import asynccontextmanager

from src.api.routes import router
from src.config.settings import get_settings
from src.core.cache import get_cache_manager
from src.utils.logging import setup_logging
from src.utils.exceptions import setup_exception_handlers


# 应用程序生命周期管理
@asynccontextmanager
async def lifespan(app: FastAPI):
    """应用程序启动和关闭时的生命周期管理"""
    # 启动时初始化
    settings = get_settings()
    setup_logging(settings.LOG_LEVEL)
    
    # 初始化缓存管理器
    cache_manager = get_cache_manager()
    await cache_manager.initialize()
    
    print("UQM Backend 服务启动完成")
    
    yield
    
    # 关闭时清理资源
    await cache_manager.close()
    print("UQM Backend 服务已关闭")


def create_app() -> FastAPI:
    """创建FastAPI应用程序实例"""
    settings = get_settings()
    
    # 创建FastAPI应用实例
    app = FastAPI(
        title="UQM Backend API",
        description="统一查询模型(UQM)后端执行引擎",
        version="0.1.0",
        docs_url="/docs" if settings.DEBUG else None,
        redoc_url="/redoc" if settings.DEBUG else None,
        lifespan=lifespan
    )
    
    # 配置CORS中间件
    if settings.CORS_ORIGINS:
        app.add_middleware(
            CORSMiddleware,
            allow_origins=settings.CORS_ORIGINS,
            allow_credentials=settings.CORS_CREDENTIALS,
            allow_methods=settings.CORS_METHODS,
            allow_headers=settings.CORS_HEADERS,
        )
    
    # 配置信任主机中间件
    if settings.ALLOWED_HOSTS:
        app.add_middleware(
            TrustedHostMiddleware,
            allowed_hosts=settings.ALLOWED_HOSTS
        )
    
    # 注册路由
    app.include_router(router, prefix="/api/v1")
    
    # 设置异常处理器
    setup_exception_handlers(app)
    
    return app


# 创建应用实例
app = create_app()


def main():
    """主函数 - 启动应用程序"""
    settings = get_settings()
    
    uvicorn.run(
        "src.main:app",
        host=settings.HOST,
        port=settings.PORT,
        reload=settings.DEBUG,
        log_level=settings.LOG_LEVEL.lower(),
        access_log=True,
        workers=1 if settings.DEBUG else 4
    )


if __name__ == "__main__":
    main()

================
File: uqm-backend/src/steps/assert_step.py
================
"""
数据断言步骤实现
用于验证数据质量和业务规则
"""

from typing import Any, Dict, List, Optional, Union
import pandas as pd
import re

from src.steps.base import BaseStep
from src.utils.exceptions import ValidationError, ExecutionError


class AssertStep(BaseStep):
    """断言步骤执行器"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        初始化断言步骤
        
        Args:
            config: 断言步骤配置
        """
        super().__init__(config)
        
        # 支持的断言类型
        self.supported_assertions = {
            'row_count': self._assert_row_count,
            'not_null': self._assert_not_null,
            'unique': self._assert_unique,
            'range': self._assert_range,
            'regex': self._assert_regex,
            'custom': self._assert_custom,
            'column_exists': self._assert_column_exists,
            'data_type': self._assert_data_type,
            'value_in': self._assert_value_in,
            'relationship': self._assert_relationship
        }
    
    def validate(self) -> None:
        """验证断言步骤配置"""
        required_fields = ["source", "assertions"]
        self._validate_required_config(required_fields)
        
        # 验证assertions字段
        assertions = self.config.get("assertions")
        if not isinstance(assertions, list):
            raise ValidationError("assertions必须是数组")
        
        # 验证每个断言
        for i, assertion in enumerate(assertions):
            if not isinstance(assertion, dict):
                raise ValidationError(f"断言 {i} 必须是对象")
            
            assertion_type = assertion.get("type")
            if not assertion_type:
                raise ValidationError(f"断言 {i} 缺少type字段")
            
            if assertion_type not in self.supported_assertions:
                raise ValidationError(f"不支持的断言类型: {assertion_type}")
    
    async def execute(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        执行断言步骤
        
        Args:
            context: 执行上下文
            
        Returns:
            源数据（断言通过时）
        """
        try:
            # 获取源数据
            source_name = self.config["source"]
            source_data = context["get_source_data"](source_name)
            
            # 执行断言检查
            assertion_results = self._perform_assertions(source_data)
            
            # 处理断言结果
            self._handle_assertion_results(assertion_results)
            
            # 断言通过，返回原始数据
            return source_data
            
        except Exception as e:
            self.log_error("断言步骤执行失败", error=str(e))
            raise ExecutionError(f"断言执行失败: {e}")
    
    def _perform_assertions(self, source_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        执行断言检查
        
        Args:
            source_data: 源数据
            
        Returns:
            断言结果列表
        """
        assertions = self.config["assertions"]
        assertion_results = []
        
        for assertion in assertions:
            try:
                assertion_type = assertion["type"]
                assertion_func = self.supported_assertions[assertion_type]
                
                # 执行断言
                result = assertion_func(source_data, assertion)
                
                assertion_results.append({
                    "type": assertion_type,
                    "passed": result.get("passed", True),
                    "message": result.get("message", ""),
                    "details": result.get("details", {})
                })
                
            except Exception as e:
                assertion_results.append({
                    "type": assertion.get("type", "unknown"),
                    "passed": False,
                    "message": str(e),
                    "details": {"error": str(e)}
                })
        
        return assertion_results
    
    def _handle_assertion_results(self, assertion_results: List[Dict[str, Any]]) -> None:
        """
        处理断言结果
        
        Args:
            assertion_results: 断言结果列表
        """
        failed_assertions = [r for r in assertion_results if not r["passed"]]
        
        if failed_assertions:
            # 生成断言报告
            report = self._generate_assertion_report(assertion_results)
            
            # 根据配置决定如何处理失败
            on_failure = self.config.get("on_failure", "error")
            
            if on_failure == "error":
                # 抛出异常
                raise ExecutionError(f"断言检查失败:\n{report}")
            elif on_failure == "warning":
                # 记录警告
                self.log_warning("断言检查失败", report=report)
            elif on_failure == "ignore":
                # 忽略失败
                self.log_info("断言检查失败但被忽略", report=report)
        else:
            self.log_info("所有断言检查通过")
    
    def _assert_row_count(self, data: List[Dict[str, Any]], assertion: Dict[str, Any]) -> Dict[str, Any]:
        """断言行数"""
        expected_count = assertion.get("expected")
        min_count = assertion.get("min")
        max_count = assertion.get("max")
        
        actual_count = len(data)
        
        if expected_count is not None and actual_count != expected_count:
            return {
                "passed": False,
                "message": f"期望行数 {expected_count}，实际行数 {actual_count}",
                "details": {"expected": expected_count, "actual": actual_count}
            }
        
        if min_count is not None and actual_count < min_count:
            return {
                "passed": False,
                "message": f"行数少于最小值 {min_count}，实际行数 {actual_count}",
                "details": {"min": min_count, "actual": actual_count}
            }
        
        if max_count is not None and actual_count > max_count:
            return {
                "passed": False,
                "message": f"行数超过最大值 {max_count}，实际行数 {actual_count}",
                "details": {"max": max_count, "actual": actual_count}
            }
        
        return {"passed": True, "message": f"行数检查通过: {actual_count}"}
    
    def _assert_not_null(self, data: List[Dict[str, Any]], assertion: Dict[str, Any]) -> Dict[str, Any]:
        """断言非空"""
        columns = assertion.get("columns", [])
        if isinstance(columns, str):
            columns = [columns]
        
        null_records = []
        
        for i, record in enumerate(data):
            for column in columns:
                if column in record and (record[column] is None or record[column] == ""):
                    null_records.append({"row": i, "column": column, "value": record[column]})
        
        if null_records:
            return {
                "passed": False,
                "message": f"发现 {len(null_records)} 个空值",
                "details": {"null_records": null_records[:10]}  # 只显示前10个
            }
        
        return {"passed": True, "message": f"非空检查通过，检查了 {len(columns)} 列"}
    
    def _assert_unique(self, data: List[Dict[str, Any]], assertion: Dict[str, Any]) -> Dict[str, Any]:
        """断言唯一性"""
        columns = assertion.get("columns", [])
        if isinstance(columns, str):
            columns = [columns]
        
        seen_values = {}
        duplicate_records = []
        
        for i, record in enumerate(data):
            key_values = tuple(record.get(col) for col in columns)
            
            if key_values in seen_values:
                duplicate_records.append({
                    "row": i,
                    "duplicate_of": seen_values[key_values],
                    "values": dict(zip(columns, key_values))
                })
            else:
                seen_values[key_values] = i
        
        if duplicate_records:
            return {
                "passed": False,
                "message": f"发现 {len(duplicate_records)} 个重复值",
                "details": {"duplicate_records": duplicate_records[:10]}
            }
        
        return {"passed": True, "message": f"唯一性检查通过，检查了 {len(columns)} 列"}
    
    def _assert_range(self, data: List[Dict[str, Any]], assertion: Dict[str, Any]) -> Dict[str, Any]:
        """断言值范围"""
        column = assertion.get("column")
        min_value = assertion.get("min")
        max_value = assertion.get("max")
        
        out_of_range_records = []
        
        for i, record in enumerate(data):
            if column in record:
                value = record[column]
                if isinstance(value, (int, float)):
                    if min_value is not None and value < min_value:
                        out_of_range_records.append({
                            "row": i,
                            "column": column,
                            "value": value,
                            "reason": f"小于最小值 {min_value}"
                        })
                    elif max_value is not None and value > max_value:
                        out_of_range_records.append({
                            "row": i,
                            "column": column,
                            "value": value,
                            "reason": f"大于最大值 {max_value}"
                        })
        
        if out_of_range_records:
            return {
                "passed": False,
                "message": f"发现 {len(out_of_range_records)} 个超出范围的值",
                "details": {"out_of_range_records": out_of_range_records[:10]}
            }
        
        return {"passed": True, "message": f"范围检查通过，列 {column}"}
    
    def _assert_regex(self, data: List[Dict[str, Any]], assertion: Dict[str, Any]) -> Dict[str, Any]:
        """断言正则表达式匹配"""
        column = assertion.get("column")
        pattern = assertion.get("pattern")
        
        if not pattern:
            return {"passed": False, "message": "缺少pattern参数"}
        
        try:
            regex = re.compile(pattern)
        except re.error as e:
            return {"passed": False, "message": f"无效的正则表达式: {e}"}
        
        mismatch_records = []
        
        for i, record in enumerate(data):
            if column in record:
                value = str(record[column])
                if not regex.match(value):
                    mismatch_records.append({
                        "row": i,
                        "column": column,
                        "value": value
                    })
        
        if mismatch_records:
            return {
                "passed": False,
                "message": f"发现 {len(mismatch_records)} 个不匹配正则表达式的值",
                "details": {"mismatch_records": mismatch_records[:10]}
            }
        
        return {"passed": True, "message": f"正则表达式检查通过，列 {column}"}
    
    def _assert_custom(self, data: List[Dict[str, Any]], assertion: Dict[str, Any]) -> Dict[str, Any]:
        """自定义断言"""
        expression = assertion.get("expression")
        
        if not expression:
            return {"passed": False, "message": "缺少expression参数"}
        
        try:
            # 这里可以实现更复杂的自定义断言逻辑
            # 为了安全性，这里只是一个示例
            failed_rows = []
            
            for i, record in enumerate(data):
                # 简单的表达式评估（生产环境需要更安全的实现）
                try:
                    # 将记录作为局部变量传入
                    if not eval(expression, {"__builtins__": {}}, record):
                        failed_rows.append(i)
                except Exception:
                    failed_rows.append(i)
            
            if failed_rows:
                return {
                    "passed": False,
                    "message": f"自定义断言失败，{len(failed_rows)} 行不满足条件",
                    "details": {"failed_rows": failed_rows[:10]}
                }
            
            return {"passed": True, "message": "自定义断言通过"}
            
        except Exception as e:
            return {"passed": False, "message": f"自定义断言执行错误: {e}"}
    
    def _assert_column_exists(self, data: List[Dict[str, Any]], assertion: Dict[str, Any]) -> Dict[str, Any]:
        """断言列存在"""
        columns = assertion.get("columns", [])
        if isinstance(columns, str):
            columns = [columns]
        
        if not data:
            return {"passed": False, "message": "数据为空，无法检查列"}
        
        existing_columns = set(data[0].keys())
        missing_columns = [col for col in columns if col not in existing_columns]
        
        if missing_columns:
            return {
                "passed": False,
                "message": f"缺少列: {missing_columns}",
                "details": {"missing_columns": missing_columns}
            }
        
        return {"passed": True, "message": f"列存在检查通过: {columns}"}
    
    def _assert_data_type(self, data: List[Dict[str, Any]], assertion: Dict[str, Any]) -> Dict[str, Any]:
        """断言数据类型"""
        column = assertion.get("column")
        expected_type = assertion.get("expected_type")
        
        type_mapping = {
            "int": int,
            "float": float,
            "str": str,
            "bool": bool,
            "number": (int, float)
        }
        
        expected_python_type = type_mapping.get(expected_type)
        if not expected_python_type:
            return {"passed": False, "message": f"不支持的数据类型: {expected_type}"}
        
        type_errors = []
        
        for i, record in enumerate(data):
            if column in record and record[column] is not None:
                if not isinstance(record[column], expected_python_type):
                    type_errors.append({
                        "row": i,
                        "column": column,
                        "value": record[column],
                        "actual_type": type(record[column]).__name__
                    })
        
        if type_errors:
            return {
                "passed": False,
                "message": f"发现 {len(type_errors)} 个类型错误",
                "details": {"type_errors": type_errors[:10]}
            }
        
        return {"passed": True, "message": f"数据类型检查通过，列 {column}"}
    
    def _assert_value_in(self, data: List[Dict[str, Any]], assertion: Dict[str, Any]) -> Dict[str, Any]:
        """断言值在指定集合中"""
        column = assertion.get("column")
        allowed_values = assertion.get("allowed_values", [])
        
        invalid_records = []
        
        for i, record in enumerate(data):
            if column in record:
                value = record[column]
                if value not in allowed_values:
                    invalid_records.append({
                        "row": i,
                        "column": column,
                        "value": value
                    })
        
        if invalid_records:
            return {
                "passed": False,
                "message": f"发现 {len(invalid_records)} 个无效值",
                "details": {"invalid_records": invalid_records[:10]}
            }
        
        return {"passed": True, "message": f"值域检查通过，列 {column}"}
    
    def _assert_relationship(self, data: List[Dict[str, Any]], assertion: Dict[str, Any]) -> Dict[str, Any]:
        """断言字段间关系"""
        # 这是一个复杂的断言类型，可以检查字段间的关系
        # 例如：开始日期必须小于结束日期
        return {"passed": True, "message": "关系断言暂未实现"}
    
    def _generate_assertion_report(self, assertion_results: List[Dict[str, Any]]) -> str:
        """生成断言报告"""
        total_assertions = len(assertion_results)
        passed_assertions = len([r for r in assertion_results if r["passed"]])
        failed_assertions = total_assertions - passed_assertions
        
        report_lines = [
            f"断言检查报告:",
            f"总计: {total_assertions}, 通过: {passed_assertions}, 失败: {failed_assertions}",
            ""
        ]
        
        for result in assertion_results:
            status = "✓" if result["passed"] else "✗"
            report_lines.append(f"{status} {result['type']}: {result['message']}")
        
        return "\n".join(report_lines)

================
File: uqm-backend/src/steps/base.py
================
"""
步骤基类定义
定义所有步骤的抽象基类和通用功能
"""

import time
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional

from src.utils.logging import LoggerMixin
from src.utils.exceptions import ExecutionError, ValidationError


class BaseStep(ABC, LoggerMixin):
    """所有步骤的抽象基类"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        初始化步骤
        
        Args:
            config: 步骤配置
        """
        self.config = config
        self.step_name = config.get("name", self.__class__.__name__)
        
        # 验证配置
        self.validate()
    
    @abstractmethod
    async def execute(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        执行步骤（抽象方法）
        
        Args:
            context: 执行上下文
            
        Returns:
            步骤执行结果
        """
        pass
    
    @abstractmethod
    def validate(self) -> None:
        """验证步骤配置（抽象方法）"""
        pass
    
    def _prepare_context(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        准备执行上下文
        
        Args:
            context: 原始上下文
            
        Returns:
            准备好的上下文
        """
        # 添加步骤特定的上下文信息
        prepared_context = context.copy()
        prepared_context["step_config"] = self.config
        prepared_context["step_name"] = self.step_name
        
        return prepared_context
    
    def _log_execution(self, start_time: float, end_time: float, 
                      result_count: int = 0) -> None:
        """
        记录执行日志
        
        Args:
            start_time: 开始时间
            end_time: 结束时间
            result_count: 结果数量
        """
        execution_time = end_time - start_time
        
        self.log_info(
            f"步骤 {self.step_name} 执行完成",
            execution_time=execution_time,
            result_count=result_count
        )
    
    def _handle_error(self, error: Exception) -> None:
        """
        处理执行错误
        
        Args:
            error: 错误信息
        """
        self.log_error(
            f"步骤 {self.step_name} 执行失败",
            error=str(error),
            exc_info=True
        )
        
        # 根据错误类型抛出相应的异常
        if isinstance(error, (ValidationError, ExecutionError)):
            raise error
        else:
            raise ExecutionError(f"步骤 {self.step_name} 执行失败: {error}")
    
    def _validate_required_config(self, required_fields: List[str]) -> None:
        """
        验证必需的配置字段
        
        Args:
            required_fields: 必需字段列表
        """
        for field in required_fields:
            if field not in self.config:
                raise ValidationError(
                    f"步骤 {self.step_name} 缺少必需配置: {field}"
                )
    
    def _get_config_value(self, key: str, default: Any = None) -> Any:
        """
        获取配置值
        
        Args:
            key: 配置键
            default: 默认值
            
        Returns:
            配置值
        """
        return self.config.get(key, default)
    
    async def _execute_with_timing(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        带计时的执行方法
        
        Args:
            context: 执行上下文
            
        Returns:
            执行结果
        """
        start_time = time.time()
        
        try:
            self.log_info(f"开始执行步骤: {self.step_name}")
            
            # 准备上下文
            prepared_context = self._prepare_context(context)
            
            # 执行步骤
            result = await self.execute(prepared_context)
            
            end_time = time.time()
            
            # 记录执行日志
            self._log_execution(
                start_time=start_time,
                end_time=end_time,
                result_count=len(result) if result else 0
            )
            
            return result
            
        except Exception as e:
            end_time = time.time()
            self._handle_error(e)
    
    def get_step_type(self) -> str:
        """
        获取步骤类型
        
        Returns:
            步骤类型
        """
        # 从类名推断步骤类型
        class_name = self.__class__.__name__
        if class_name.endswith("Step"):
            step_type = class_name[:-4].lower()
        else:
            step_type = class_name.lower()
        
        return step_type
    
    def get_dependencies(self) -> List[str]:
        """
        获取步骤依赖
        
        Returns:
            依赖步骤列表
        """
        dependencies = []
        
        # 检查source配置
        source = self.config.get("source")
        if source:
            if isinstance(source, str):
                dependencies.append(source)
            elif isinstance(source, list):
                dependencies.extend(source)
        
        # 检查sources配置
        sources = self.config.get("sources")
        if sources and isinstance(sources, list):
            dependencies.extend(sources)
        
        return dependencies
    
    def __str__(self) -> str:
        """字符串表示"""
        return f"{self.__class__.__name__}(name={self.step_name})"
    
    def __repr__(self) -> str:
        """对象表示"""
        return f"{self.__class__.__name__}(name={self.step_name}, config={self.config})"

================
File: uqm-backend/src/steps/enrich_step.py
================
"""
数据丰富化步骤实现
通过查找表来丰富源数据
"""

from typing import Any, Dict, List, Optional, Union
import pandas as pd

from src.steps.base import BaseStep
from src.utils.exceptions import ValidationError, ExecutionError


class EnrichStep(BaseStep):
    """丰富化步骤执行器"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        初始化丰富化步骤
        
        Args:
            config: 丰富化步骤配置
        """
        super().__init__(config)
    
    def validate(self) -> None:
        """验证丰富化步骤配置"""
        required_fields = ["source", "lookup", "on"]
        self._validate_required_config(required_fields)
        
        # 验证source字段
        source = self.config.get("source")
        if not isinstance(source, str):
            raise ValidationError("source必须是字符串")
        
        # 验证lookup字段
        lookup = self.config.get("lookup")
        if not isinstance(lookup, (str, dict)):
            raise ValidationError("lookup必须是字符串或对象")
        
        # 验证on字段
        on = self.config.get("on")
        if not isinstance(on, (str, dict, list)):
            raise ValidationError("on必须是字符串、对象或数组")
    
    async def execute(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        执行丰富化步骤
        
        Args:
            context: 执行上下文
            
        Returns:
            丰富化后的数据
        """
        try:
            # 获取源数据
            source_name = self.config["source"]
            source_data = context["get_source_data"](source_name)
            
            # 获取查找表数据
            lookup_data = await self._fetch_lookup_data(context)
            
            # 执行数据丰富化
            enriched_data = self._perform_enrichment(source_data, lookup_data)
            
            return enriched_data
            
        except Exception as e:
            self.log_error("丰富化步骤执行失败", error=str(e))
            raise ExecutionError(f"丰富化执行失败: {e}")
    
    async def _fetch_lookup_data(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        获取查找表数据
        
        Args:
            context: 执行上下文
            
        Returns:
            查找表数据
        """
        lookup_config = self.config["lookup"]
        
        if isinstance(lookup_config, str):
            # 从其他步骤获取数据
            return context["get_source_data"](lookup_config)
        
        elif isinstance(lookup_config, dict):
            # 从数据库表获取数据
            table_name = lookup_config.get("table")
            if not table_name:
                raise ValidationError("lookup配置中缺少table字段")
            
            # 构建查询
            columns = lookup_config.get("columns", ["*"])
            where_conditions = lookup_config.get("where", [])
            
            # 使用SQL构建器构建查询
            from src.utils.sql_builder import SQLBuilder
            sql_builder = SQLBuilder()
            
            query = sql_builder.build_select_query(
                select_fields=columns,
                from_table=table_name,
                where_conditions=where_conditions
            )
            
            # 执行查询
            connector_manager = context["connector_manager"]
            connector = await connector_manager.get_default_connector()
            
            return await connector.execute_query(query)
        
        else:
            raise ValidationError("无效的lookup配置")
    
    def _perform_enrichment(self, source_data: List[Dict[str, Any]], 
                           lookup_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        执行数据丰富化
        
        Args:
            source_data: 源数据
            lookup_data: 查找表数据
            
        Returns:
            丰富化后的数据
        """
        try:
            if not source_data:
                return []
            
            if not lookup_data:
                self.log_warning("查找表数据为空，返回原始数据")
                return source_data
            
            # 转换为DataFrame进行处理
            source_df = pd.DataFrame(source_data)
            lookup_df = pd.DataFrame(lookup_data)
            
            # 解析连接条件
            join_config = self._parse_join_config()
            
            # 执行连接
            result_df = self._perform_join(source_df, lookup_df, join_config)
            
            # 转换回字典列表
            return result_df.to_dict('records')
            
        except Exception as e:
            self.log_error("执行数据丰富化失败", error=str(e))
            raise ExecutionError(f"数据丰富化失败: {e}")
    
    def _parse_join_config(self) -> Dict[str, Any]:
        """
        解析连接配置
        
        Returns:
            连接配置字典
        """
        on_config = self.config["on"]
        join_type = self.config.get("join_type", "left")
        
        if isinstance(on_config, str):
            # 简单字段连接
            return {
                "type": join_type,
                "left_on": on_config,
                "right_on": on_config
            }
        
        elif isinstance(on_config, dict):
            # 复杂连接配置
            return {
                "type": join_type,
                "left_on": on_config.get("left"),
                "right_on": on_config.get("right"),
                "condition": on_config.get("condition")
            }
        
        elif isinstance(on_config, list):
            # 多字段连接
            return {
                "type": join_type,
                "left_on": on_config,
                "right_on": on_config
            }
        
        else:
            raise ValidationError("无效的连接配置")
    
    def _perform_join(self, source_df: pd.DataFrame, 
                     lookup_df: pd.DataFrame,
                     join_config: Dict[str, Any]) -> pd.DataFrame:
        """
        执行DataFrame连接
        
        Args:
            source_df: 源数据DataFrame
            lookup_df: 查找表DataFrame
            join_config: 连接配置
            
        Returns:
            连接后的DataFrame
        """
        join_type = join_config["type"]
        left_on = join_config["left_on"]
        right_on = join_config["right_on"]
        
        # 验证连接键是否存在
        self._validate_join_keys(source_df, lookup_df, left_on, right_on)
        
        # 根据连接类型执行连接
        if join_type.lower() == "left":
            how = "left"
        elif join_type.lower() == "right":
            how = "right"
        elif join_type.lower() == "inner":
            how = "inner"
        elif join_type.lower() == "outer":
            how = "outer"
        else:
            how = "left"  # 默认左连接
        
        # 执行连接
        result_df = source_df.merge(
            lookup_df,
            left_on=left_on,
            right_on=right_on,
            how=how,
            suffixes=('', '_lookup')
        )
        
        # 处理列名冲突
        result_df = self._handle_column_conflicts(result_df)
        
        return result_df
    
    def _validate_join_keys(self, source_df: pd.DataFrame, 
                           lookup_df: pd.DataFrame,
                           left_on: Union[str, List[str]],
                           right_on: Union[str, List[str]]) -> None:
        """
        验证连接键是否存在
        
        Args:
            source_df: 源数据DataFrame
            lookup_df: 查找表DataFrame
            left_on: 左连接键
            right_on: 右连接键
        """
        # 验证左连接键
        if isinstance(left_on, str):
            left_keys = [left_on]
        else:
            left_keys = left_on
        
        for key in left_keys:
            if key not in source_df.columns:
                raise ValidationError(f"源数据中不存在连接键: {key}")
        
        # 验证右连接键
        if isinstance(right_on, str):
            right_keys = [right_on]
        else:
            right_keys = right_on
        
        for key in right_keys:
            if key not in lookup_df.columns:
                raise ValidationError(f"查找表中不存在连接键: {key}")
    
    def _handle_column_conflicts(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        处理列名冲突
        
        Args:
            df: 原始DataFrame
            
        Returns:
            处理后的DataFrame
        """
        # 获取需要重命名的列
        columns_to_rename = {}
        for col in df.columns:
            if col.endswith('_lookup'):
                original_name = col[:-7]  # 移除'_lookup'后缀
                new_name = self._get_unique_column_name(df, original_name)
                columns_to_rename[col] = new_name
        
        # 重命名列
        if columns_to_rename:
            df = df.rename(columns=columns_to_rename)
        
        return df
    
    def _get_unique_column_name(self, df: pd.DataFrame, base_name: str) -> str:
        """
        获取唯一的列名
        
        Args:
            df: DataFrame
            base_name: 基础名称
            
        Returns:
            唯一的列名
        """
        if base_name not in df.columns:
            return base_name
        
        counter = 1
        while True:
            new_name = f"{base_name}_{counter}"
            if new_name not in df.columns:
                return new_name
            counter += 1
    
    def _optimize_lookup_strategy(self, source_size: int, lookup_size: int) -> str:
        """
        优化查找策略
        
        Args:
            source_size: 源数据大小
            lookup_size: 查找表大小
            
        Returns:
            优化策略
        """
        # 根据数据大小选择不同的策略
        if source_size < 1000 and lookup_size < 1000:
            return "memory_join"
        elif lookup_size < 10000:
            return "hash_join"
        else:
            return "merge_join"
    
    def _handle_missing_keys(self, result_df: pd.DataFrame) -> pd.DataFrame:
        """
        处理缺失键值
        
        Args:
            result_df: 结果DataFrame
            
        Returns:
            处理后的DataFrame
        """
        missing_strategy = self.config.get("missing_strategy", "keep")
        
        if missing_strategy == "drop":
            # 删除包含缺失值的行
            result_df = result_df.dropna()
        elif missing_strategy == "fill":
            # 用默认值填充缺失值
            fill_value = self.config.get("fill_value", "")
            result_df = result_df.fillna(fill_value)
        # "keep"策略：保持缺失值不变
        
        return result_df

================
File: uqm-backend/src/steps/pivot_step.py
================
"""
数据透视步骤实现
将数据从长格式转换为宽格式
"""

from typing import Any, Dict, List, Optional, Union
import pandas as pd
import numpy as np

from src.steps.base import BaseStep
from src.utils.exceptions import ValidationError, ExecutionError


class PivotStep(BaseStep):
    """透视步骤执行器"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        初始化透视步骤
        
        Args:
            config: 透视步骤配置
        """
        super().__init__(config)
        
        # 支持的聚合函数
        self.supported_agg_functions = {
            'sum': np.sum,
            'mean': np.mean,
            'avg': np.mean,
            'count': np.size,
            'min': np.min,
            'max': np.max,
            'std': np.std,
            'var': np.var,
            'first': lambda x: x.iloc[0] if len(x) > 0 else None,
            'last': lambda x: x.iloc[-1] if len(x) > 0 else None
        }
    
    def validate(self) -> None:
        """验证透视步骤配置"""
        required_fields = ["source", "index", "columns", "values"]
        self._validate_required_config(required_fields)
        
        # 验证source字段
        source = self.config.get("source")
        if not isinstance(source, str):
            raise ValidationError("source必须是字符串")
        
        # 验证index字段
        index = self.config.get("index")
        if not isinstance(index, (str, list)):
            raise ValidationError("index必须是字符串或数组")
        
        # 验证columns字段
        columns = self.config.get("columns")
        if not isinstance(columns, (str, list)):
            raise ValidationError("columns必须是字符串或数组")
        
        # 验证values字段
        values = self.config.get("values")
        if not isinstance(values, (str, list)):
            raise ValidationError("values必须是字符串或数组")
        
        # 验证聚合函数
        agg_func = self.config.get("agg_func", "sum")
        if isinstance(agg_func, str):
            if agg_func.lower() not in self.supported_agg_functions:
                raise ValidationError(f"不支持的聚合函数: {agg_func}")
        elif isinstance(agg_func, dict):
            for func in agg_func.values():
                if func.lower() not in self.supported_agg_functions:
                    raise ValidationError(f"不支持的聚合函数: {func}")
    
    async def execute(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        执行透视步骤
        
        Args:
            context: 执行上下文
            
        Returns:
            透视后的数据
        """
        try:
            # 获取源数据
            source_name = self.config["source"]
            source_data = context["get_source_data"](source_name)
            
            if not source_data:
                self.log_warning("源数据为空")
                return []
            
            # 执行数据透视
            pivoted_data = self._perform_pivot(source_data)
            
            return pivoted_data
            
        except Exception as e:
            self.log_error("透视步骤执行失败", error=str(e))
            raise ExecutionError(f"透视执行失败: {e}")
    
    def _perform_pivot(self, source_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        执行数据透视
        
        Args:
            source_data: 源数据
            
        Returns:
            透视后的数据
        """
        try:
            # 转换为DataFrame
            df = pd.DataFrame(source_data)
            
            # 获取透视参数
            index = self.config["index"]
            columns = self.config["columns"]
            values = self.config["values"]
            agg_func = self.config.get("agg_func", "sum")
            fill_value = self.config.get("fill_value", 0)
            
            # 验证透视列是否存在
            self._validate_pivot_columns(df, index, columns, values)
            
            # 准备透视数据
            df_clean = self._prepare_pivot_data(df, index, columns, values)
            
            # 执行透视
            if isinstance(agg_func, str):
                # 单一聚合函数
                agg_function = self.supported_agg_functions[agg_func.lower()]
                pivot_df = df_clean.pivot_table(
                    index=index,
                    columns=columns,
                    values=values,
                    aggfunc=agg_function,
                    fill_value=fill_value
                )
            else:
                # 多个聚合函数
                agg_functions = {
                    val: self.supported_agg_functions[func.lower()]
                    for val, func in agg_func.items()
                }
                pivot_df = df_clean.pivot_table(
                    index=index,
                    columns=columns,
                    values=list(agg_functions.keys()),
                    aggfunc=agg_functions,
                    fill_value=fill_value
                )
            
            # 处理多级列名
            pivot_df = self._flatten_column_names(pivot_df)
            
            # 重置索引
            pivot_df = pivot_df.reset_index()
            
            # 转换回字典列表
            result = pivot_df.to_dict('records')
            
            self.log_info(
                "透视操作完成",
                original_rows=len(df),
                pivoted_rows=len(result),
                pivoted_columns=len(pivot_df.columns)
            )
            
            return result
            
        except Exception as e:
            self.log_error("执行透视操作失败", error=str(e))
            raise ExecutionError(f"透视操作失败: {e}")
    
    def _validate_pivot_columns(self, df: pd.DataFrame, 
                               index: Union[str, List[str]],
                               columns: Union[str, List[str]],
                               values: Union[str, List[str]]) -> None:
        """
        验证透视列是否存在
        
        Args:
            df: 数据DataFrame
            index: 索引列
            columns: 透视列
            values: 值列
        """
        # 收集所有需要的列
        required_columns = []
        
        if isinstance(index, str):
            required_columns.append(index)
        else:
            required_columns.extend(index)
        
        if isinstance(columns, str):
            required_columns.append(columns)
        else:
            required_columns.extend(columns)
        
        if isinstance(values, str):
            required_columns.append(values)
        else:
            required_columns.extend(values)
        
        # 验证列是否存在
        missing_columns = []
        for col in required_columns:
            if col not in df.columns:
                missing_columns.append(col)
        
        if missing_columns:
            raise ValidationError(f"数据中缺少以下列: {missing_columns}")
    
    def _prepare_pivot_data(self, df: pd.DataFrame,
                           index: Union[str, List[str]],
                           columns: Union[str, List[str]],
                           values: Union[str, List[str]]) -> pd.DataFrame:
        """
        准备透视数据
        
        Args:
            df: 原始DataFrame
            index: 索引列
            columns: 透视列
            values: 值列
            
        Returns:
            准备好的DataFrame
        """
        # 选择需要的列
        required_columns = []
        
        if isinstance(index, str):
            required_columns.append(index)
        else:
            required_columns.extend(index)
        
        if isinstance(columns, str):
            required_columns.append(columns)
        else:
            required_columns.extend(columns)
        
        if isinstance(values, str):
            required_columns.append(values)
        else:
            required_columns.extend(values)
        
        # 去重列名
        required_columns = list(set(required_columns))
        
        # 选择列
        df_clean = df[required_columns].copy()
        
        # 处理缺失值
        missing_strategy = self.config.get("missing_strategy", "drop")
        if missing_strategy == "drop":
            df_clean = df_clean.dropna()
        elif missing_strategy == "fill":
            fill_value = self.config.get("missing_fill_value", 0)
            df_clean = df_clean.fillna(fill_value)
        
        # 处理数据类型
        if isinstance(values, str):
            value_columns = [values]
        else:
            value_columns = values
        
        for col in value_columns:
            if col in df_clean.columns:
                # 尝试转换为数值类型
                df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')
        
        return df_clean
    
    def _flatten_column_names(self, pivot_df: pd.DataFrame) -> pd.DataFrame:
        """
        展平多级列名
        
        Args:
            pivot_df: 透视后的DataFrame
            
        Returns:
            列名展平后的DataFrame
        """
        if isinstance(pivot_df.columns, pd.MultiIndex):
            # 处理多级列名
            new_columns = []
            for col in pivot_df.columns:
                if isinstance(col, tuple):
                    # 组合列名
                    col_name = "_".join([str(c) for c in col if str(c) != ""])
                    new_columns.append(col_name)
                else:
                    new_columns.append(str(col))
            
            pivot_df.columns = new_columns
        
        return pivot_df
    
    def _handle_null_values(self, pivot_df: pd.DataFrame) -> pd.DataFrame:
        """
        处理透视后的空值
        
        Args:
            pivot_df: 透视后的DataFrame
            
        Returns:
            处理空值后的DataFrame
        """
        null_strategy = self.config.get("null_strategy", "keep")
        
        if null_strategy == "drop":
            # 删除包含空值的行
            pivot_df = pivot_df.dropna()
        elif null_strategy == "fill":
            # 用指定值填充空值
            fill_value = self.config.get("null_fill_value", 0)
            pivot_df = pivot_df.fillna(fill_value)
        elif null_strategy == "zero":
            # 用0填充空值
            pivot_df = pivot_df.fillna(0)
        # "keep"策略：保持空值不变
        
        return pivot_df
    
    def _format_pivot_result(self, pivot_df: pd.DataFrame) -> pd.DataFrame:
        """
        格式化透视结果
        
        Args:
            pivot_df: 透视后的DataFrame
            
        Returns:
            格式化后的DataFrame
        """
        # 处理列名
        column_prefix = self.config.get("column_prefix", "")
        column_suffix = self.config.get("column_suffix", "")
        
        if column_prefix or column_suffix:
            new_columns = {}
            for col in pivot_df.columns:
                if col not in self.config.get("index", []):
                    new_col = f"{column_prefix}{col}{column_suffix}"
                    new_columns[col] = new_col
            
            if new_columns:
                pivot_df = pivot_df.rename(columns=new_columns)
        
        # 排序
        sort_by = self.config.get("sort_by")
        if sort_by:
            if isinstance(sort_by, str):
                sort_columns = [sort_by]
            else:
                sort_columns = sort_by
            
            # 验证排序列是否存在
            valid_sort_columns = [col for col in sort_columns if col in pivot_df.columns]
            if valid_sort_columns:
                sort_ascending = self.config.get("sort_ascending", True)
                pivot_df = pivot_df.sort_values(valid_sort_columns, ascending=sort_ascending)
        
        return pivot_df

================
File: uqm-backend/src/steps/query_step.py
================
"""
查询步骤实现
负责执行SQL查询并返回结果
"""

from typing import Any, Dict, List, Optional, Union

from src.steps.base import BaseStep
from src.utils.sql_builder import SQLBuilder
from src.utils.exceptions import ValidationError, ExecutionError


class QueryStep(BaseStep):
    """查询步骤执行器"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        初始化查询步骤
        
        Args:
            config: 查询步骤配置
        """
        super().__init__(config)
        self.sql_builder = SQLBuilder()
    
    def validate(self) -> None:
        """验证查询步骤配置"""
        required_fields = ["data_source"]
        self._validate_required_config(required_fields)
        
        # 验证数据源
        data_source = self.config.get("data_source")
        if not isinstance(data_source, str):
            raise ValidationError("data_source必须是字符串")
        
        # 验证维度字段
        dimensions = self.config.get("dimensions", [])
        if not isinstance(dimensions, list):
            raise ValidationError("dimensions必须是数组")
        
        # 验证指标字段
        metrics = self.config.get("metrics", [])
        if not isinstance(metrics, list):
            raise ValidationError("metrics必须是数组")
        
        # 至少需要有维度或指标
        if not dimensions and not metrics:
            raise ValidationError("至少需要指定dimensions或metrics")
    
    async def execute(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        执行查询步骤
        
        Args:
            context: 执行上下文
            
        Returns:
            查询结果
        """
        try:
            # 获取连接器管理器
            connector_manager = context["connector_manager"]
            
            # 构建SQL查询
            query = self.build_query()
            
            # 获取默认连接器（或根据配置选择特定连接器）
            connector = await connector_manager.get_default_connector()
            
            # 执行查询
            result = await connector.execute_query(query)
            
            return result
            
        except Exception as e:
            self.log_error("查询步骤执行失败", error=str(e))
            raise ExecutionError(f"查询执行失败: {e}")
    
    def build_query(self) -> str:
        """
        构建SQL查询
        
        Returns:
            SQL查询语句
        """
        try:
            data_source = self.config["data_source"]
            dimensions = self.config.get("dimensions", [])
            metrics = self.config.get("metrics", [])
            filters = self.config.get("filters", [])
            joins = self.config.get("joins", [])
            group_by = self.config.get("group_by", [])
            having = self.config.get("having", [])
            order_by = self.config.get("order_by", [])
            limit = self.config.get("limit")
            offset = self.config.get("offset")
            
            # 构建SELECT子句
            select_fields = []
            
            # 添加维度字段
            for dim in dimensions:
                if isinstance(dim, str):
                    select_fields.append(dim)
                elif isinstance(dim, dict):
                    field_expr = self._build_field_expression(dim)
                    select_fields.append(field_expr)
            
            # 添加指标字段
            for metric in metrics:
                if isinstance(metric, str):
                    select_fields.append(metric)
                elif isinstance(metric, dict):
                    metric_expr = self._build_metric_expression(metric)
                    select_fields.append(metric_expr)
            
            # 添加计算字段
            calculated_fields = self.config.get("calculated_fields", [])
            for calc_field in calculated_fields:
                calc_expr = self._build_calculated_field(calc_field)
                select_fields.append(calc_expr)
            
            if not select_fields:
                select_fields = ["*"]
            
            # 使用SQL构建器构建查询
            query = self.sql_builder.build_select_query(
                select_fields=select_fields,
                from_table=data_source,
                joins=joins,
                where_conditions=filters,
                group_by=group_by,
                having=having,
                order_by=order_by,
                limit=limit,
                offset=offset
            )
            
            self.log_debug("构建的SQL查询", query=query)
            return query
            
        except Exception as e:
            self.log_error("构建SQL查询失败", error=str(e))
            raise ValidationError(f"构建查询失败: {e}")
    
    def _build_field_expression(self, field_config: Dict[str, Any]) -> str:
        """
        构建字段表达式
        
        Args:
            field_config: 字段配置
            
        Returns:
            字段表达式
        """
        name = field_config.get("name")
        alias = field_config.get("alias")
        expression = field_config.get("expression")
        
        if expression:
            # 使用自定义表达式
            result = expression
        elif name:
            # 使用字段名
            result = name
        else:
            raise ValidationError("字段配置必须包含name或expression")
        
        # 添加别名
        if alias:
            result = f"{result} AS {alias}"
        
        return result
    
    def _build_metric_expression(self, metric_config: Dict[str, Any]) -> str:
        """
        构建指标表达式
        
        Args:
            metric_config: 指标配置
            
        Returns:
            指标表达式
        """
        name = metric_config.get("name")
        alias = metric_config.get("alias", name)
        agg_function = metric_config.get("aggregation", "SUM")
        expression = metric_config.get("expression")
        
        if expression:
            # 使用自定义表达式
            result = expression
        elif name:
            # 使用聚合函数
            result = f"{agg_function}({name})"
        else:
            raise ValidationError("指标配置必须包含name或expression")
        
        # 添加别名
        if alias:
            result = f"{result} AS {alias}"
        
        return result
    
    def _build_calculated_field(self, calc_config: Dict[str, Any]) -> str:
        """
        构建计算字段表达式
        
        Args:
            calc_config: 计算字段配置
            
        Returns:
            计算字段表达式
        """
        alias = calc_config.get("alias")
        expression = calc_config.get("expression")
        
        if not expression:
            raise ValidationError("计算字段必须包含expression")
        
        if not alias:
            raise ValidationError("计算字段必须包含alias")
        
        return f"{expression} AS {alias}"
    
    def _build_window_function(self, window_config: Dict[str, Any]) -> str:
        """
        构建窗口函数表达式
        
        Args:
            window_config: 窗口函数配置
            
        Returns:
            窗口函数表达式
        """
        function = window_config.get("function")
        partition_by = window_config.get("partition_by", [])
        order_by = window_config.get("order_by", [])
        alias = window_config.get("alias")
        
        if not function:
            raise ValidationError("窗口函数必须指定function")
        
        # 构建窗口函数表达式
        window_expr = function
        
        # 添加OVER子句
        over_parts = []
        
        if partition_by:
            partition_clause = "PARTITION BY " + ", ".join(partition_by)
            over_parts.append(partition_clause)
        
        if order_by:
            if isinstance(order_by, list):
                order_clause = "ORDER BY " + ", ".join(order_by)
            else:
                order_clause = f"ORDER BY {order_by}"
            over_parts.append(order_clause)
        
        if over_parts:
            over_clause = " ".join(over_parts)
        else:
            over_clause = ""
        
        result = f"{window_expr} OVER ({over_clause})"
        
        # 添加别名
        if alias:
            result = f"{result} AS {alias}"
        
        return result

================
File: uqm-backend/src/steps/union_step.py
================
"""
集合合并步骤实现
负责合并多个数据集
"""

from typing import Any, Dict, List, Optional, Union
import pandas as pd

from src.steps.base import BaseStep
from src.utils.exceptions import ValidationError, ExecutionError


class UnionStep(BaseStep):
    """合并步骤执行器"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        初始化合并步骤
        
        Args:
            config: 合并步骤配置
        """
        super().__init__(config)
    
    def validate(self) -> None:
        """验证合并步骤配置"""
        required_fields = ["sources"]
        self._validate_required_config(required_fields)
        
        # 验证sources字段
        sources = self.config.get("sources")
        if not isinstance(sources, list) or len(sources) < 2:
            raise ValidationError("sources必须是包含至少2个元素的数组")
        
        # 验证模式
        mode = self.config.get("mode", "union")
        if mode not in ["union", "union_all", "intersect", "except"]:
            raise ValidationError("mode必须是union、union_all、intersect或except之一")
    
    async def execute(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        执行合并步骤
        
        Args:
            context: 执行上下文
            
        Returns:
            合并后的数据
        """
        try:
            # 获取源数据
            sources = self.config["sources"]
            source_datasets = context["get_source_data"](sources)
            
            # 执行数据合并
            result = self._perform_union(source_datasets)
            
            return result
            
        except Exception as e:
            self.log_error("合并步骤执行失败", error=str(e))
            raise ExecutionError(f"合并执行失败: {e}")
    
    def _perform_union(self, source_datasets: Dict[str, List[Dict[str, Any]]]) -> List[Dict[str, Any]]:
        """
        执行数据合并
        
        Args:
            source_datasets: 源数据集字典
            
        Returns:
            合并后的数据
        """
        try:
            mode = self.config.get("mode", "union")
            
            if mode == "union":
                return self._union_distinct(source_datasets)
            elif mode == "union_all":
                return self._union_all(source_datasets)
            elif mode == "intersect":
                return self._intersect(source_datasets)
            elif mode == "except":
                return self._except(source_datasets)
            else:
                raise ValidationError(f"不支持的合并模式: {mode}")
                
        except Exception as e:
            self.log_error("执行数据合并失败", error=str(e))
            raise ExecutionError(f"数据合并失败: {e}")
    
    def _union_all(self, source_datasets: Dict[str, List[Dict[str, Any]]]) -> List[Dict[str, Any]]:
        """执行UNION ALL操作（保留重复）"""
        all_data = []
        
        # 验证并对齐列结构
        aligned_datasets = self._align_columns(source_datasets)
        
        for source_name, data in aligned_datasets.items():
            # 为每条记录添加来源标识（如果配置了）
            if self.config.get("add_source_column", False):
                source_column = self.config.get("source_column", "_source")
                for record in data:
                    record[source_column] = source_name
            
            all_data.extend(data)
        
        return all_data
    
    def _union_distinct(self, source_datasets: Dict[str, List[Dict[str, Any]]]) -> List[Dict[str, Any]]:
        """执行UNION操作（去除重复）"""
        # 先执行UNION ALL
        all_data = self._union_all(source_datasets)
        
        # 去除重复数据
        return self._remove_duplicates(all_data)
    
    def _intersect(self, source_datasets: Dict[str, List[Dict[str, Any]]]) -> List[Dict[str, Any]]:
        """执行INTERSECT操作（交集）"""
        if len(source_datasets) < 2:
            return []
        
        # 获取第一个数据集作为基准
        datasets = list(source_datasets.values())
        result_set = set()
        
        # 将第一个数据集转换为集合
        for record in datasets[0]:
            record_tuple = self._record_to_tuple(record)
            result_set.add(record_tuple)
        
        # 与其他数据集求交集
        for dataset in datasets[1:]:
            dataset_set = set()
            for record in dataset:
                record_tuple = self._record_to_tuple(record)
                dataset_set.add(record_tuple)
            
            result_set = result_set.intersection(dataset_set)
        
        # 转换回字典列表
        return [self._tuple_to_record(t, datasets[0][0].keys()) for t in result_set]
    
    def _except(self, source_datasets: Dict[str, List[Dict[str, Any]]]) -> List[Dict[str, Any]]:
        """执行EXCEPT操作（差集）"""
        if len(source_datasets) < 2:
            return list(source_datasets.values())[0] if source_datasets else []
        
        datasets = list(source_datasets.values())
        
        # 获取第一个数据集
        result_set = set()
        for record in datasets[0]:
            record_tuple = self._record_to_tuple(record)
            result_set.add(record_tuple)
        
        # 从结果中移除其他数据集的记录
        for dataset in datasets[1:]:
            for record in dataset:
                record_tuple = self._record_to_tuple(record)
                result_set.discard(record_tuple)
        
        # 转换回字典列表
        return [self._tuple_to_record(t, datasets[0][0].keys()) for t in result_set]
    
    def _align_columns(self, source_datasets: Dict[str, List[Dict[str, Any]]]) -> Dict[str, List[Dict[str, Any]]]:
        """对齐列结构"""
        if not source_datasets:
            return source_datasets
        
        # 收集所有列名
        all_columns = set()
        for data in source_datasets.values():
            if data:
                all_columns.update(data[0].keys())
        
        # 对齐每个数据集的列
        aligned_datasets = {}
        for source_name, data in source_datasets.items():
            aligned_data = []
            for record in data:
                aligned_record = {}
                for col in all_columns:
                    aligned_record[col] = record.get(col, None)
                aligned_data.append(aligned_record)
            aligned_datasets[source_name] = aligned_data
        
        return aligned_datasets
    
    def _remove_duplicates(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """移除重复数据"""
        seen = set()
        unique_data = []
        
        for record in data:
            record_tuple = self._record_to_tuple(record)
            if record_tuple not in seen:
                seen.add(record_tuple)
                unique_data.append(record)
        
        return unique_data
    
    def _record_to_tuple(self, record: Dict[str, Any]) -> tuple:
        """将记录转换为元组（用于集合操作）"""
        return tuple(sorted(record.items()))
    
    def _tuple_to_record(self, record_tuple: tuple, columns: List[str]) -> Dict[str, Any]:
        """将元组转换回记录"""
        return dict(record_tuple)
    
    def _validate_schema_compatibility(self, source_datasets: Dict[str, List[Dict[str, Any]]]) -> None:
        """验证模式兼容性"""
        if not source_datasets:
            return
        
        # 获取第一个数据集的列结构作为基准
        first_dataset = list(source_datasets.values())[0]
        if not first_dataset:
            return
        
        base_columns = set(first_dataset[0].keys())
        
        # 检查其他数据集的列结构
        for source_name, data in source_datasets.items():
            if data:
                current_columns = set(data[0].keys())
                
                # 根据配置决定如何处理列差异
                strict_mode = self.config.get("strict_schema", False)
                if strict_mode and current_columns != base_columns:
                    missing_in_current = base_columns - current_columns
                    extra_in_current = current_columns - base_columns
                    
                    error_msg = f"数据集 {source_name} 的列结构不匹配"
                    if missing_in_current:
                        error_msg += f"，缺少列: {missing_in_current}"
                    if extra_in_current:
                        error_msg += f"，多余列: {extra_in_current}"
                    
                    raise ValidationError(error_msg)
    
    def _optimize_union_strategy(self, source_datasets: Dict[str, List[Dict[str, Any]]]) -> str:
        """优化合并策略"""
        total_records = sum(len(data) for data in source_datasets.values())
        dataset_count = len(source_datasets)
        
        if total_records < 10000 and dataset_count <= 5:
            return "memory_union"
        elif total_records < 100000:
            return "streaming_union"
        else:
            return "chunked_union"

================
File: uqm-backend/src/steps/unpivot_step.py
================
"""
数据逆透视步骤实现
将数据从宽格式转换为长格式
"""

from typing import Any, Dict, List, Optional, Union
import pandas as pd

from src.steps.base import BaseStep
from src.utils.exceptions import ValidationError, ExecutionError


class UnpivotStep(BaseStep):
    """逆透视步骤执行器"""
    
    def __init__(self, config: Dict[str, Any]):
        """初始化逆透视步骤"""
        super().__init__(config)
    
    def validate(self) -> None:
        """验证逆透视步骤配置"""
        required_fields = ["source", "id_vars", "value_vars"]
        self._validate_required_config(required_fields)
    
    async def execute(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """执行逆透视步骤"""
        try:
            # 获取源数据
            source_name = self.config["source"]
            source_data = context["get_source_data"](source_name)
            
            if not source_data:
                return []
            
            # 执行逆透视
            result = self._perform_unpivot(source_data)
            return result
            
        except Exception as e:
            self.log_error("逆透视步骤执行失败", error=str(e))
            raise ExecutionError(f"逆透视执行失败: {e}")
    
    def _perform_unpivot(self, source_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """执行逆透视操作"""
        df = pd.DataFrame(source_data)
        
        id_vars = self.config["id_vars"]
        value_vars = self.config["value_vars"]
        var_name = self.config.get("var_name", "variable")
        value_name = self.config.get("value_name", "value")
        
        # 执行melt操作
        melted_df = df.melt(
            id_vars=id_vars,
            value_vars=value_vars,
            var_name=var_name,
            value_name=value_name
        )
        
        return melted_df.to_dict('records')


class UnionStep(BaseStep):
    """合并步骤执行器"""
    
    def __init__(self, config: Dict[str, Any]):
        """初始化合并步骤"""
        super().__init__(config)
    
    def validate(self) -> None:
        """验证合并步骤配置"""
        required_fields = ["sources"]
        self._validate_required_config(required_fields)
    
    async def execute(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """执行合并步骤"""
        try:
            sources = self.config["sources"]
            source_datasets = context["get_source_data"](sources)
            
            # 执行数据合并
            result = self._perform_union(source_datasets)
            return result
            
        except Exception as e:
            self.log_error("合并步骤执行失败", error=str(e))
            raise ExecutionError(f"合并执行失败: {e}")
    
    def _perform_union(self, source_datasets: Dict[str, List[Dict[str, Any]]]) -> List[Dict[str, Any]]:
        """执行数据合并"""
        all_data = []
        
        for source_name, data in source_datasets.items():
            # 为每条记录添加来源标识
            if self.config.get("add_source_column", False):
                source_column = self.config.get("source_column", "source")
                for record in data:
                    record[source_column] = source_name
            
            all_data.extend(data)
        
        # 处理重复数据
        if self.config.get("remove_duplicates", False):
            # 简单去重（转换为字符串比较）
            seen = set()
            unique_data = []
            for record in all_data:
                record_str = str(sorted(record.items()))
                if record_str not in seen:
                    seen.add(record_str)
                    unique_data.append(record)
            return unique_data
        
        return all_data


class AssertStep(BaseStep):
    """断言步骤执行器"""
    
    def __init__(self, config: Dict[str, Any]):
        """初始化断言步骤"""
        super().__init__(config)
    
    def validate(self) -> None:
        """验证断言步骤配置"""
        required_fields = ["source", "assertions"]
        self._validate_required_config(required_fields)
    
    async def execute(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """执行断言步骤"""
        try:
            # 获取源数据
            source_name = self.config["source"]
            source_data = context["get_source_data"](source_name)
            
            # 执行断言检查
            self._perform_assertions(source_data)
            
            # 断言通过，返回原始数据
            return source_data
            
        except Exception as e:
            self.log_error("断言步骤执行失败", error=str(e))
            raise ExecutionError(f"断言执行失败: {e}")
    
    def _perform_assertions(self, source_data: List[Dict[str, Any]]) -> None:
        """执行断言检查"""
        assertions = self.config["assertions"]
        
        for assertion in assertions:
            assertion_type = assertion.get("type")
            
            if assertion_type == "row_count":
                self._assert_row_count(source_data, assertion)
            elif assertion_type == "not_null":
                self._assert_not_null(source_data, assertion)
            elif assertion_type == "unique":
                self._assert_unique(source_data, assertion)
            elif assertion_type == "range":
                self._assert_range(source_data, assertion)
            else:
                self.log_warning(f"未知的断言类型: {assertion_type}")
    
    def _assert_row_count(self, data: List[Dict[str, Any]], assertion: Dict[str, Any]) -> None:
        """断言行数"""
        expected_count = assertion.get("expected")
        min_count = assertion.get("min")
        max_count = assertion.get("max")
        
        actual_count = len(data)
        
        if expected_count is not None and actual_count != expected_count:
            raise ExecutionError(f"行数断言失败: 期望{expected_count}，实际{actual_count}")
        
        if min_count is not None and actual_count < min_count:
            raise ExecutionError(f"最小行数断言失败: 期望至少{min_count}，实际{actual_count}")
        
        if max_count is not None and actual_count > max_count:
            raise ExecutionError(f"最大行数断言失败: 期望最多{max_count}，实际{actual_count}")
    
    def _assert_not_null(self, data: List[Dict[str, Any]], assertion: Dict[str, Any]) -> None:
        """断言非空"""
        columns = assertion.get("columns", [])
        
        for record in data:
            for column in columns:
                if column in record and (record[column] is None or record[column] == ""):
                    raise ExecutionError(f"非空断言失败: 列 {column} 包含空值")
    
    def _assert_unique(self, data: List[Dict[str, Any]], assertion: Dict[str, Any]) -> None:
        """断言唯一性"""
        columns = assertion.get("columns", [])
        
        seen_values = set()
        for record in data:
            key_values = tuple(record.get(col) for col in columns)
            if key_values in seen_values:
                raise ExecutionError(f"唯一性断言失败: 列 {columns} 存在重复值")
            seen_values.add(key_values)
    
    def _assert_range(self, data: List[Dict[str, Any]], assertion: Dict[str, Any]) -> None:
        """断言值范围"""
        column = assertion.get("column")
        min_value = assertion.get("min")
        max_value = assertion.get("max")
        
        for record in data:
            if column in record:
                value = record[column]
                if isinstance(value, (int, float)):
                    if min_value is not None and value < min_value:
                        raise ExecutionError(f"范围断言失败: 列 {column} 值 {value} 小于最小值 {min_value}")
                    if max_value is not None and value > max_value:
                        raise ExecutionError(f"范围断言失败: 列 {column} 值 {value} 大于最大值 {max_value}")

================
File: uqm-backend/src/utils/exceptions.py
================
"""
异常处理模块
定义自定义异常类和异常处理器
"""

from typing import Any, Dict
from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException

from src.utils.logging import get_logger

logger = get_logger(__name__)


class UQMBaseException(Exception):
    """UQM基础异常类"""
    
    def __init__(self, message: str, error_code: str = None, details: Dict[str, Any] = None):
        self.message = message
        self.error_code = error_code or self.__class__.__name__
        self.details = details or {}
        super().__init__(self.message)


class ValidationError(UQMBaseException):
    """数据验证异常"""
    pass


class ExecutionError(UQMBaseException):
    """执行异常"""
    pass


class ConnectionError(UQMBaseException):
    """连接异常"""
    pass


class CacheError(UQMBaseException):
    """缓存异常"""
    pass


class ParseError(UQMBaseException):
    """解析异常"""
    pass


class TimeoutError(UQMBaseException):
    """超时异常"""
    pass


def setup_exception_handlers(app: FastAPI) -> None:
    """设置全局异常处理器"""
    
    @app.exception_handler(UQMBaseException)
    async def uqm_exception_handler(request: Request, exc: UQMBaseException) -> JSONResponse:
        """UQM自定义异常处理器"""
        logger.error(
            "UQM异常",
            error_code=exc.error_code,
            message=exc.message,
            details=exc.details,
            path=request.url.path,
            method=request.method
        )
        
        return JSONResponse(
            status_code=400,
            content={
                "error": {
                    "code": exc.error_code,
                    "message": exc.message,
                    "details": exc.details
                }
            }
        )
    
    @app.exception_handler(RequestValidationError)
    async def validation_exception_handler(request: Request, exc: RequestValidationError) -> JSONResponse:
        """请求验证异常处理器"""
        logger.error(
            "请求验证异常",
            errors=exc.errors(),
            path=request.url.path,
            method=request.method
        )
        
        return JSONResponse(
            status_code=422,
            content={
                "error": {
                    "code": "VALIDATION_ERROR",
                    "message": "请求数据验证失败",
                    "details": exc.errors()
                }
            }
        )
    
    @app.exception_handler(StarletteHTTPException)
    async def http_exception_handler(request: Request, exc: StarletteHTTPException) -> JSONResponse:
        """HTTP异常处理器"""
        logger.error(
            "HTTP异常",
            status_code=exc.status_code,
            detail=exc.detail,
            path=request.url.path,
            method=request.method
        )
        
        return JSONResponse(
            status_code=exc.status_code,
            content={
                "error": {
                    "code": f"HTTP_{exc.status_code}",
                    "message": exc.detail,
                    "details": {}
                }
            }
        )
    
    @app.exception_handler(Exception)
    async def general_exception_handler(request: Request, exc: Exception) -> JSONResponse:
        """通用异常处理器"""
        logger.error(
            "未处理异常",
            exception_type=type(exc).__name__,
            exception_message=str(exc),
            path=request.url.path,
            method=request.method,
            exc_info=True
        )
        
        return JSONResponse(
            status_code=500,
            content={
                "error": {
                    "code": "INTERNAL_SERVER_ERROR",
                    "message": "服务器内部错误",
                    "details": {}
                }
            }
        )

================
File: uqm-backend/src/utils/expression_parser.py
================
"""
表达式解析器模块

提供安全的表达式解析和执行功能，支持数据转换、计算、条件判断等操作。
"""

import ast
import re
import operator
import math
import pandas as pd
from typing import Any, Dict, List, Optional, Union, Callable, Tuple
from datetime import datetime, date, timedelta
from decimal import Decimal
import logging

from ..utils.exceptions import ExpressionError, ValidationError

logger = logging.getLogger(__name__)


class SafeExpressionEvaluator(ast.NodeVisitor):
    """安全的表达式求值器"""
    
    # 允许的操作符
    ALLOWED_OPERATORS = {
        # 算术运算符
        ast.Add: operator.add,
        ast.Sub: operator.sub,
        ast.Mult: operator.mul,
        ast.Div: operator.truediv,
        ast.FloorDiv: operator.floordiv,
        ast.Mod: operator.mod,
        ast.Pow: operator.pow,
        
        # 比较运算符
        ast.Eq: operator.eq,
        ast.NotEq: operator.ne,
        ast.Lt: operator.lt,
        ast.LtE: operator.le,
        ast.Gt: operator.gt,
        ast.GtE: operator.ge,
        
        # 逻辑运算符
        ast.And: lambda x, y: x and y,
        ast.Or: lambda x, y: x or y,
        
        # 位运算符
        ast.BitAnd: operator.and_,
        ast.BitOr: operator.or_,
        ast.BitXor: operator.xor,
        
        # 一元运算符
        ast.UAdd: operator.pos,
        ast.USub: operator.neg,
        ast.Not: operator.not_,
        ast.Invert: operator.inv,
    }
    
    # 允许的内置函数
    ALLOWED_BUILTINS = {
        'abs': abs,
        'round': round,
        'max': max,
        'min': min,
        'sum': sum,
        'len': len,
        'int': int,
        'float': float,
        'str': str,
        'bool': bool,
        'list': list,
        'dict': dict,
        'tuple': tuple,
        'set': set,
    }
    
    # 允许的数学函数
    ALLOWED_MATH_FUNCTIONS = {
        'sqrt': math.sqrt,
        'ceil': math.ceil,
        'floor': math.floor,
        'sin': math.sin,
        'cos': math.cos,
        'tan': math.tan,
        'log': math.log,
        'log10': math.log10,
        'exp': math.exp,
        'pow': math.pow,
        'pi': math.pi,
        'e': math.e,
    }
    
    def __init__(self, context: Dict[str, Any] = None):
        self.context = context or {}
        self.allowed_names = set(self.context.keys())
        self.allowed_names.update(self.ALLOWED_BUILTINS.keys())
        self.allowed_names.update(self.ALLOWED_MATH_FUNCTIONS.keys())
    
    def evaluate(self, expression: str) -> Any:
        """安全地执行表达式"""
        try:
            # 解析表达式为 AST
            tree = ast.parse(expression, mode='eval')
            # 访问并执行 AST
            return self.visit(tree.body)
        except SyntaxError as e:
            raise ExpressionError(f"表达式语法错误: {str(e)}")
        except Exception as e:
            raise ExpressionError(f"表达式执行错误: {str(e)}")
    
    def visit_Expression(self, node):
        """访问表达式节点"""
        return self.visit(node.body)
    
    def visit_Constant(self, node):
        """访问常量节点"""
        return node.value
    
    def visit_Num(self, node):
        """访问数字节点（Python < 3.8）"""
        return node.n
    
    def visit_Str(self, node):
        """访问字符串节点（Python < 3.8）"""
        return node.s
    
    def visit_Name(self, node):
        """访问名称节点"""
        name = node.id
        
        # 检查是否在允许的名称列表中
        if name not in self.allowed_names:
            raise ExpressionError(f"不允许访问变量或函数: {name}")
        
        # 返回相应的值
        if name in self.context:
            return self.context[name]
        elif name in self.ALLOWED_BUILTINS:
            return self.ALLOWED_BUILTINS[name]
        elif name in self.ALLOWED_MATH_FUNCTIONS:
            return self.ALLOWED_MATH_FUNCTIONS[name]
        else:
            raise ExpressionError(f"未定义的变量: {name}")
    
    def visit_BinOp(self, node):
        """访问二元操作节点"""
        op_type = type(node.op)
        
        if op_type not in self.ALLOWED_OPERATORS:
            raise ExpressionError(f"不允许的操作符: {op_type.__name__}")
        
        left = self.visit(node.left)
        right = self.visit(node.right)
        
        try:
            return self.ALLOWED_OPERATORS[op_type](left, right)
        except ZeroDivisionError:
            raise ExpressionError("除零错误")
        except Exception as e:
            raise ExpressionError(f"操作执行错误: {str(e)}")
    
    def visit_UnaryOp(self, node):
        """访问一元操作节点"""
        op_type = type(node.op)
        
        if op_type not in self.ALLOWED_OPERATORS:
            raise ExpressionError(f"不允许的一元操作符: {op_type.__name__}")
        
        operand = self.visit(node.operand)
        
        try:
            return self.ALLOWED_OPERATORS[op_type](operand)
        except Exception as e:
            raise ExpressionError(f"一元操作执行错误: {str(e)}")
    
    def visit_Compare(self, node):
        """访问比较操作节点"""
        left = self.visit(node.left)
        
        for op, comparator in zip(node.ops, node.comparators):
            op_type = type(op)
            
            if op_type not in self.ALLOWED_OPERATORS:
                raise ExpressionError(f"不允许的比较操作符: {op_type.__name__}")
            
            right = self.visit(comparator)
            
            try:
                result = self.ALLOWED_OPERATORS[op_type](left, right)
                if not result:
                    return False
                left = right
            except Exception as e:
                raise ExpressionError(f"比较操作执行错误: {str(e)}")
        
        return True
    
    def visit_BoolOp(self, node):
        """访问布尔操作节点"""
        op_type = type(node.op)
        
        if op_type == ast.And:
            for value in node.values:
                result = self.visit(value)
                if not result:
                    return False
            return True
        elif op_type == ast.Or:
            for value in node.values:
                result = self.visit(value)
                if result:
                    return True
            return False
        else:
            raise ExpressionError(f"不允许的布尔操作符: {op_type.__name__}")
    
    def visit_Call(self, node):
        """访问函数调用节点"""
        func_name = None
        
        if isinstance(node.func, ast.Name):
            func_name = node.func.id
        else:
            raise ExpressionError("不支持复杂的函数调用")
        
        # 检查函数是否被允许
        if func_name not in self.allowed_names:
            raise ExpressionError(f"不允许调用函数: {func_name}")
        
        # 获取函数对象
        if func_name in self.ALLOWED_BUILTINS:
            func = self.ALLOWED_BUILTINS[func_name]
        elif func_name in self.ALLOWED_MATH_FUNCTIONS:
            func = self.ALLOWED_MATH_FUNCTIONS[func_name]
        elif func_name in self.context and callable(self.context[func_name]):
            func = self.context[func_name]
        else:
            raise ExpressionError(f"函数不可调用: {func_name}")
        
        # 计算参数
        args = [self.visit(arg) for arg in node.args]
        kwargs = {kw.arg: self.visit(kw.value) for kw in node.keywords}
        
        try:
            return func(*args, **kwargs)
        except Exception as e:
            raise ExpressionError(f"函数调用错误 {func_name}: {str(e)}")
    
    def visit_List(self, node):
        """访问列表节点"""
        return [self.visit(item) for item in node.elts]
    
    def visit_Tuple(self, node):
        """访问元组节点"""
        return tuple(self.visit(item) for item in node.elts)
    
    def visit_Dict(self, node):
        """访问字典节点"""
        return {
            self.visit(key): self.visit(value)
            for key, value in zip(node.keys, node.values)
        }
    
    def visit_Subscript(self, node):
        """访问下标节点"""
        value = self.visit(node.value)
        index = self.visit(node.slice)
        
        try:
            return value[index]
        except Exception as e:
            raise ExpressionError(f"下标访问错误: {str(e)}")
    
    def visit_Slice(self, node):
        """访问切片节点"""
        lower = self.visit(node.lower) if node.lower else None
        upper = self.visit(node.upper) if node.upper else None
        step = self.visit(node.step) if node.step else None
        
        return slice(lower, upper, step)
    
    def visit_Index(self, node):
        """访问索引节点（Python < 3.9）"""
        return self.visit(node.value)
    
    def generic_visit(self, node):
        """访问未知节点类型"""
        raise ExpressionError(f"不支持的表达式节点类型: {type(node).__name__}")


class ExpressionParser:
    """表达式解析器"""
    
    def __init__(self):
        self.functions = {}
        self.variables = {}
        self._register_default_functions()
    
    def _register_default_functions(self):
        """注册默认函数"""
        # 字符串函数
        self.functions.update({
            'upper': lambda x: str(x).upper(),
            'lower': lambda x: str(x).lower(),
            'strip': lambda x: str(x).strip(),
            'split': lambda x, sep=' ': str(x).split(sep),
            'replace': lambda x, old, new: str(x).replace(old, new),
            'startswith': lambda x, prefix: str(x).startswith(prefix),
            'endswith': lambda x, suffix: str(x).endswith(suffix),
            'contains': lambda x, substr: substr in str(x),
            'length': lambda x: len(str(x)),
        })
        
        # 日期时间函数
        self.functions.update({
            'now': lambda: datetime.now(),
            'today': lambda: date.today(),
            'year': lambda x: x.year if isinstance(x, (date, datetime)) else None,
            'month': lambda x: x.month if isinstance(x, (date, datetime)) else None,
            'day': lambda x: x.day if isinstance(x, (date, datetime)) else None,
            'weekday': lambda x: x.weekday() if isinstance(x, (date, datetime)) else None,
            'strftime': lambda x, fmt: x.strftime(fmt) if isinstance(x, (date, datetime)) else None,
        })
        
        # 类型转换函数
        self.functions.update({
            'to_int': lambda x: int(x) if x is not None else None,
            'to_float': lambda x: float(x) if x is not None else None,
            'to_str': lambda x: str(x) if x is not None else None,
            'to_bool': lambda x: bool(x) if x is not None else None,
        })
        
        # 条件函数
        self.functions.update({
            'if_null': lambda x, default: default if x is None else x,
            'if_empty': lambda x, default: default if not x else x,
            'coalesce': lambda *args: next((arg for arg in args if arg is not None), None),
        })
        
        # 数组函数
        self.functions.update({
            'first': lambda arr: arr[0] if arr else None,
            'last': lambda arr: arr[-1] if arr else None,
            'join': lambda arr, sep=',': sep.join(str(x) for x in arr),
            'sort': lambda arr: sorted(arr),
            'unique': lambda arr: list(set(arr)),
        })
    
    def register_function(self, name: str, func: Callable):
        """注册自定义函数"""
        if not callable(func):
            raise ValueError(f"函数 {name} 必须是可调用对象")
        
        self.functions[name] = func
        logger.debug(f"注册自定义函数: {name}")
    
    def set_variable(self, name: str, value: Any):
        """设置变量值"""
        self.variables[name] = value
    
    def set_variables(self, variables: Dict[str, Any]):
        """批量设置变量"""
        self.variables.update(variables)
    
    def parse_and_evaluate(self, expression: str, context: Dict[str, Any] = None) -> Any:
        """解析并执行表达式"""
        # 合并上下文
        full_context = self.variables.copy()
        full_context.update(self.functions)
        if context:
            full_context.update(context)
        
        # 创建求值器
        evaluator = SafeExpressionEvaluator(full_context)
        
        # 执行表达式
        return evaluator.evaluate(expression)
    
    def validate_expression(self, expression: str) -> Tuple[bool, str]:
        """验证表达式语法"""
        try:
            # 检查是否包含危险模式
            dangerous_patterns = [
                r'__\w+__',  # 双下划线属性
                r'import\s+',  # import 语句
                r'exec\s*\(',  # exec 函数
                r'eval\s*\(',  # eval 函数
                r'open\s*\(',  # open 函数
                r'file\s*\(',  # file 函数
            ]
            
            for pattern in dangerous_patterns:
                if re.search(pattern, expression, re.IGNORECASE):
                    return False, f"表达式包含危险模式: {pattern}"
            
            # 解析语法
            ast.parse(expression, mode='eval')
            return True, ""
            
        except SyntaxError as e:
            return False, f"语法错误: {str(e)}"
        except Exception as e:
            return False, f"验证失败: {str(e)}"


class DataFrameExpressionParser(ExpressionParser):
    """DataFrame 表达式解析器"""
    
    def __init__(self):
        super().__init__()
        self._register_dataframe_functions()
    
    def _register_dataframe_functions(self):
        """注册 DataFrame 相关函数"""
        # 聚合函数
        self.functions.update({
            'sum_col': lambda df, col: df[col].sum() if col in df.columns else 0,
            'mean_col': lambda df, col: df[col].mean() if col in df.columns else 0,
            'count_col': lambda df, col: df[col].count() if col in df.columns else 0,
            'max_col': lambda df, col: df[col].max() if col in df.columns else None,
            'min_col': lambda df, col: df[col].min() if col in df.columns else None,
        })
        
        # 条件筛选函数
        self.functions.update({
            'filter_rows': lambda df, condition: df.query(condition),
            'select_cols': lambda df, cols: df[cols] if isinstance(cols, list) else df[[cols]],
            'drop_cols': lambda df, cols: df.drop(columns=cols),
        })
    
    def apply_to_dataframe(self, df: pd.DataFrame, expression: str, 
                          column_name: str = None) -> Union[pd.DataFrame, pd.Series, Any]:
        """将表达式应用到 DataFrame"""
        try:
            # 设置 DataFrame 作为上下文变量
            context = {'df': df}
            
            # 添加列作为变量
            for col in df.columns:
                context[col] = df[col]
            
            # 解析并执行表达式
            result = self.parse_and_evaluate(expression, context)
            
            # 如果结果是标量且指定了列名，创建新列
            if column_name and not isinstance(result, (pd.DataFrame, pd.Series)):
                if isinstance(result, (list, tuple)):
                    if len(result) == len(df):
                        df[column_name] = result
                        return df
                    else:
                        raise ExpressionError(f"结果长度 {len(result)} 与 DataFrame 行数 {len(df)} 不匹配")
                else:
                    df[column_name] = result
                    return df
            
            return result
            
        except Exception as e:
            raise ExpressionError(f"DataFrame 表达式执行失败: {str(e)}")
    
    def create_computed_column(self, df: pd.DataFrame, column_name: str, 
                              expression: str) -> pd.DataFrame:
        """创建计算列"""
        # 为每行创建上下文并执行表达式
        results = []
        
        for index, row in df.iterrows():
            # 创建行上下文
            context = row.to_dict()
            context['index'] = index
            
            try:
                result = self.parse_and_evaluate(expression, context)
                results.append(result)
            except Exception as e:
                logger.warning(f"第 {index} 行表达式执行失败: {str(e)}")
                results.append(None)
        
        # 添加新列
        df_copy = df.copy()
        df_copy[column_name] = results
        
        return df_copy
    
    def filter_dataframe(self, df: pd.DataFrame, condition: str) -> pd.DataFrame:
        """根据条件筛选 DataFrame"""
        try:
            # 使用 pandas query 方法进行筛选
            return df.query(condition)
        except Exception as e:
            # 如果 query 失败，尝试使用自定义解析
            try:
                mask_results = []
                
                for index, row in df.iterrows():
                    context = row.to_dict()
                    context['index'] = index
                    
                    result = self.parse_and_evaluate(condition, context)
                    mask_results.append(bool(result))
                
                return df[mask_results]
                
            except Exception as e2:
                raise ExpressionError(f"条件筛选失败: {str(e2)}")


class SQLExpressionParser:
    """SQL 表达式解析器"""
    
    def __init__(self):
        self.sql_functions = {
            # 字符串函数
            'UPPER': 'UPPER',
            'LOWER': 'LOWER',
            'TRIM': 'TRIM',
            'LENGTH': 'LENGTH',
            'SUBSTRING': 'SUBSTRING',
            'CONCAT': 'CONCAT',
            'REPLACE': 'REPLACE',
            
            # 数值函数
            'ABS': 'ABS',
            'ROUND': 'ROUND',
            'CEIL': 'CEIL',
            'FLOOR': 'FLOOR',
            'SQRT': 'SQRT',
            'POWER': 'POWER',
            
            # 日期函数
            'NOW': 'NOW',
            'CURRENT_DATE': 'CURRENT_DATE',
            'YEAR': 'YEAR',
            'MONTH': 'MONTH',
            'DAY': 'DAY',
            'DATE_ADD': 'DATE_ADD',
            'DATE_SUB': 'DATE_SUB',
            
            # 聚合函数
            'SUM': 'SUM',
            'COUNT': 'COUNT',
            'AVG': 'AVG',
            'MAX': 'MAX',
            'MIN': 'MIN',
            'GROUP_CONCAT': 'GROUP_CONCAT',
            
            # 条件函数
            'CASE': 'CASE',
            'IF': 'IF',
            'IFNULL': 'IFNULL',
            'COALESCE': 'COALESCE',
        }
    
    def convert_expression_to_sql(self, expression: str, 
                                 dialect: str = 'standard') -> str:
        """将表达式转换为 SQL"""
        # 简化实现，实际应该根据不同数据库方言进行转换
        sql_expression = expression
        
        # 替换一些常见的 Python 表达式为 SQL
        replacements = {
            ' and ': ' AND ',
            ' or ': ' OR ',
            ' not ': ' NOT ',
            '==': '=',
            '!=': '<>',
            'True': '1',
            'False': '0',
            'None': 'NULL',
        }
        
        for old, new in replacements.items():
            sql_expression = sql_expression.replace(old, new)
        
        return sql_expression
    
    def validate_sql_expression(self, expression: str) -> Tuple[bool, str]:
        """验证 SQL 表达式"""
        try:
            # 检查基本语法
            if not expression.strip():
                return False, "表达式不能为空"
            
            # 检查平衡的括号
            if expression.count('(') != expression.count(')'):
                return False, "括号不匹配"
            
            # 检查引号
            single_quotes = expression.count("'")
            double_quotes = expression.count('"')
            
            if single_quotes % 2 != 0:
                return False, "单引号不匹配"
            
            if double_quotes % 2 != 0:
                return False, "双引号不匹配"
            
            return True, ""
            
        except Exception as e:
            return False, f"SQL 表达式验证失败: {str(e)}"


# 全局解析器实例
expression_parser = ExpressionParser()
dataframe_expression_parser = DataFrameExpressionParser()
sql_expression_parser = SQLExpressionParser()

================
File: uqm-backend/src/utils/logging.py
================
"""
日志配置模块
负责设置结构化日志记录
"""

import sys
import structlog
from typing import Any, Dict


def setup_logging(log_level: str = "INFO") -> None:
    """
    设置结构化日志记录
    
    Args:
        log_level: 日志级别
    """
    # 配置structlog
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.processors.JSONRenderer()
        ],
        context_class=structlog.threadlocal.wrap_dict(dict),
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )


def get_logger(name: str) -> structlog.stdlib.BoundLogger:
    """
    获取日志记录器实例
    
    Args:
        name: 日志记录器名称
        
    Returns:
        结构化日志记录器实例
    """
    return structlog.get_logger(name)


class LoggerMixin:
    """日志记录器混入类"""
    
    @property
    def logger(self) -> structlog.stdlib.BoundLogger:
        """获取类专用的日志记录器"""
        return get_logger(self.__class__.__name__)
    
    def log_info(self, message: str, **kwargs: Any) -> None:
        """记录信息日志"""
        self.logger.info(message, **kwargs)
    
    def log_error(self, message: str, **kwargs: Any) -> None:
        """记录错误日志"""
        self.logger.error(message, **kwargs)
    
    def log_warning(self, message: str, **kwargs: Any) -> None:
        """记录警告日志"""
        self.logger.warning(message, **kwargs)
    
    def log_debug(self, message: str, **kwargs: Any) -> None:
        """记录调试日志"""
        self.logger.debug(message, **kwargs)

================
File: uqm-backend/src/utils/sql_builder.py
================
"""
SQL查询构建工具
提供构建各种SQL查询的功能
"""

from typing import Any, Dict, List, Optional, Union
from enum import Enum

from src.utils.logging import LoggerMixin
from src.utils.exceptions import ValidationError


class SQLDialect(Enum):
    """SQL方言枚举"""
    STANDARD = "standard"
    POSTGRESQL = "postgresql"
    MYSQL = "mysql"
    SQLITE = "sqlite"


class SQLBuilder(LoggerMixin):
    """SQL查询构建器"""
    
    def __init__(self, dialect: SQLDialect = SQLDialect.STANDARD):
        """
        初始化SQL构建器
        
        Args:
            dialect: SQL方言
        """
        self.dialect = dialect
    
    def build_select_query(self, 
                          select_fields: List[str],
                          from_table: str,
                          joins: Optional[List[Dict[str, Any]]] = None,
                          where_conditions: Optional[List[Dict[str, Any]]] = None,
                          group_by: Optional[List[str]] = None,
                          having: Optional[List[Dict[str, Any]]] = None,
                          order_by: Optional[List[Union[str, Dict[str, Any]]]] = None,
                          limit: Optional[int] = None,
                          offset: Optional[int] = None) -> str:
        """
        构建SELECT查询
        
        Args:
            select_fields: 选择字段列表
            from_table: 源表名
            joins: JOIN条件列表
            where_conditions: WHERE条件列表
            group_by: GROUP BY字段列表
            having: HAVING条件列表
            order_by: ORDER BY字段列表
            limit: 限制行数
            offset: 偏移量
            
        Returns:
            SQL查询语句
        """
        try:
            query_parts = []
            
            # SELECT子句
            select_clause = self._build_select_clause(select_fields)
            query_parts.append(select_clause)
            
            # FROM子句
            from_clause = self._build_from_clause(from_table)
            query_parts.append(from_clause)
            
            # JOIN子句
            if joins:
                join_clause = self._build_join_clause(joins)
                if join_clause:
                    query_parts.append(join_clause)
            
            # WHERE子句
            if where_conditions:
                where_clause = self._build_where_clause(where_conditions)
                if where_clause:
                    query_parts.append(where_clause)
            
            # GROUP BY子句
            if group_by:
                group_by_clause = self._build_group_by_clause(group_by)
                query_parts.append(group_by_clause)
            
            # HAVING子句
            if having:
                having_clause = self._build_having_clause(having)
                if having_clause:
                    query_parts.append(having_clause)
            
            # ORDER BY子句
            if order_by:
                order_by_clause = self._build_order_by_clause(order_by)
                if order_by_clause:
                    query_parts.append(order_by_clause)
            
            # LIMIT子句
            if limit is not None:
                limit_clause = self._build_limit_clause(limit, offset)
                if limit_clause:
                    query_parts.append(limit_clause)
            
            # 组合查询
            query = "\n".join(query_parts)
            
            return query
            
        except Exception as e:
            self.log_error("构建SELECT查询失败", error=str(e))
            raise ValidationError(f"构建SELECT查询失败: {e}")
    
    def _build_select_clause(self, select_fields: List[str]) -> str:
        """构建SELECT子句"""
        if not select_fields:
            return "SELECT *"
        
        return f"SELECT {', '.join(select_fields)}"
    
    def _build_from_clause(self, from_table: str) -> str:
        """构建FROM子句"""
        return f"FROM {from_table}"
    
    def _build_join_clause(self, joins: List[Dict[str, Any]]) -> str:
        """构建JOIN子句"""
        join_parts = []
        
        for join in joins:
            join_type = join.get("type", "INNER")
            table = join.get("table")
            condition = join.get("on")
            
            if not table or not condition:
                continue
            
            # 构建连接条件
            join_condition = self._build_join_condition(condition)
            join_part = f"{join_type} JOIN {table} ON {join_condition}"
            join_parts.append(join_part)
        
        return "\n".join(join_parts)
    
    def _build_where_clause(self, where_conditions: List[Dict[str, Any]]) -> str:
        """构建WHERE子句"""
        if not where_conditions:
            return ""
        
        conditions = []
        for condition in where_conditions:
            condition_str = self._build_condition(condition)
            if condition_str:
                conditions.append(condition_str)
        
        if not conditions:
            return ""
        
        return f"WHERE {' AND '.join(conditions)}"
    
    def _build_group_by_clause(self, group_by: List[str]) -> str:
        """构建GROUP BY子句"""
        if not group_by:
            return ""
        
        return f"GROUP BY {', '.join(group_by)}"
    
    def _build_having_clause(self, having: List[Dict[str, Any]]) -> str:
        """构建HAVING子句"""
        if not having:
            return ""
        
        conditions = []
        for condition in having:
            condition_str = self._build_condition(condition)
            if condition_str:
                conditions.append(condition_str)
        
        if not conditions:
            return ""
        
        return f"HAVING {' AND '.join(conditions)}"
    
    def _build_order_by_clause(self, order_by: List[Union[str, Dict[str, Any]]]) -> str:
        """构建ORDER BY子句"""
        if not order_by:
            return ""
        
        order_parts = []
        for order_item in order_by:
            if isinstance(order_item, str):
                order_parts.append(order_item)
            elif isinstance(order_item, dict):
                field = order_item.get("field")
                direction = order_item.get("direction", "ASC")
                if field:
                    order_parts.append(f"{field} {direction}")
        
        if not order_parts:
            return ""
        
        return f"ORDER BY {', '.join(order_parts)}"
    
    def _build_limit_clause(self, limit: int, offset: Optional[int] = None) -> str:
        """构建LIMIT子句"""
        if self.dialect == SQLDialect.MYSQL:
            if offset is not None:
                return f"LIMIT {offset}, {limit}"
            else:
                return f"LIMIT {limit}"
        
        elif self.dialect == SQLDialect.POSTGRESQL:
            if offset is not None:
                return f"LIMIT {limit} OFFSET {offset}"
            else:
                return f"LIMIT {limit}"
        
        elif self.dialect == SQLDialect.SQLITE:
            if offset is not None:
                return f"LIMIT {limit} OFFSET {offset}"
            else:
                return f"LIMIT {limit}"
        
        else:
            # 标准SQL
            if offset is not None:
                return f"LIMIT {limit} OFFSET {offset}"
            else:
                return f"LIMIT {limit}"
    
    def _build_join_condition(self, condition: Union[str, Dict[str, Any]]) -> str:
        """构建连接条件"""
        if isinstance(condition, str):
            return condition
        
        elif isinstance(condition, dict):
            left = condition.get("left")
            right = condition.get("right")
            operator = condition.get("operator", "=")
            
            if left and right:
                return f"{left} {operator} {right}"
        
        return ""
    
    def _build_condition(self, condition: Union[str, Dict[str, Any]]) -> str:
        """构建条件表达式"""
        if isinstance(condition, str):
            return condition
        
        elif isinstance(condition, dict):
            field = condition.get("field")
            operator = condition.get("operator", "=")
            value = condition.get("value")
            
            if not field:
                return ""
            
            # 处理不同的操作符
            if operator.upper() == "IN":
                if isinstance(value, list):
                    value_str = ", ".join([self._format_value(v) for v in value])
                    return f"{field} IN ({value_str})"
                else:
                    return f"{field} IN ({self._format_value(value)})"
            
            elif operator.upper() == "BETWEEN":
                if isinstance(value, list) and len(value) == 2:
                    return f"{field} BETWEEN {self._format_value(value[0])} AND {self._format_value(value[1])}"
            
            elif operator.upper() == "LIKE":
                return f"{field} LIKE {self._format_value(value)}"
            
            elif operator.upper() == "IS NULL":
                return f"{field} IS NULL"
            
            elif operator.upper() == "IS NOT NULL":
                return f"{field} IS NOT NULL"
            
            else:
                return f"{field} {operator} {self._format_value(value)}"
        
        return ""
    
    def _format_value(self, value: Any) -> str:
        """格式化值"""
        if value is None:
            return "NULL"
        elif isinstance(value, str):
            # 转义单引号
            escaped_value = value.replace("'", "''")
            return f"'{escaped_value}'"
        elif isinstance(value, bool):
            return "TRUE" if value else "FALSE"
        elif isinstance(value, (int, float)):
            return str(value)
        else:
            return f"'{str(value)}'"
    
    def build_insert_query(self, table_name: str, data: Dict[str, Any]) -> str:
        """构建INSERT查询"""
        columns = list(data.keys())
        values = [self._format_value(data[col]) for col in columns]
        
        columns_str = ", ".join(columns)
        values_str = ", ".join(values)
        
        return f"INSERT INTO {table_name} ({columns_str}) VALUES ({values_str})"
    
    def build_update_query(self, table_name: str, 
                          updates: Dict[str, Any],
                          where_conditions: List[Dict[str, Any]]) -> str:
        """构建UPDATE查询"""
        set_parts = []
        for column, value in updates.items():
            set_parts.append(f"{column} = {self._format_value(value)}")
        
        set_clause = ", ".join(set_parts)
        where_clause = self._build_where_clause(where_conditions)
        
        query = f"UPDATE {table_name} SET {set_clause}"
        if where_clause:
            query += f" {where_clause}"
        
        return query
    
    def build_delete_query(self, table_name: str, 
                          where_conditions: List[Dict[str, Any]]) -> str:
        """构建DELETE查询"""
        where_clause = self._build_where_clause(where_conditions)
        
        query = f"DELETE FROM {table_name}"
        if where_clause:
            query += f" {where_clause}"
        
        return query

================
File: uqm-backend/src/utils/validators.py
================
"""
数据验证工具模块

提供各种数据验证功能，包括 UQM 配置验证、数据格式验证、业务逻辑验证等。
"""

import re
import json
import pandas as pd
from typing import Any, Dict, List, Optional, Union, Tuple
from datetime import datetime, date
from decimal import Decimal, InvalidOperation
import logging

from ..utils.exceptions import ValidationError

logger = logging.getLogger(__name__)


class DataValidator:
    """数据验证器基类"""
    
    def __init__(self):
        self.errors = []
    
    def add_error(self, field: str, message: str, value: Any = None):
        """添加验证错误"""
        self.errors.append({
            'field': field,
            'message': message,
            'value': value,
            'timestamp': datetime.now().isoformat()
        })
    
    def clear_errors(self):
        """清空错误列表"""
        self.errors = []
    
    def has_errors(self) -> bool:
        """检查是否有验证错误"""
        return len(self.errors) > 0
    
    def get_errors(self) -> List[Dict[str, Any]]:
        """获取所有验证错误"""
        return self.errors.copy()
    
    def raise_if_errors(self):
        """如果有错误则抛出异常"""
        if self.has_errors():
            raise ValidationError(f"验证失败: {len(self.errors)} 个错误", details=self.errors)


class UQMValidator(DataValidator):
    """UQM 配置验证器"""
    
    # 支持的步骤类型
    SUPPORTED_STEP_TYPES = {
        'query', 'enrich', 'pivot', 'unpivot', 'union', 'assert',
        'filter', 'sort', 'group', 'aggregate', 'join', 'transform'
    }
    
    # 支持的数据源类型
    SUPPORTED_DATASOURCE_TYPES = {
        'postgres', 'mysql', 'sqlite', 'oracle', 'sqlserver',
        'mongodb', 'redis', 'elasticsearch', 'api', 'file'
    }
    
    def validate_uqm_config(self, config: Dict[str, Any]) -> bool:
        """验证完整的 UQM 配置"""
        self.clear_errors()
        
        # 验证根级字段
        self._validate_root_fields(config)
        
        # 验证数据源配置
        if 'datasources' in config:
            self._validate_datasources(config['datasources'])
        
        # 验证步骤配置
        if 'steps' in config:
            self._validate_steps(config['steps'])
        
        # 验证输出配置
        if 'output' in config:
            self._validate_output(config['output'])
        
        return not self.has_errors()
    
    def _validate_root_fields(self, config: Dict[str, Any]):
        """验证根级必需字段"""
        required_fields = ['name', 'version', 'steps']
        
        for field in required_fields:
            if field not in config:
                self.add_error(field, f"缺少必需字段: {field}")
        
        # 验证版本格式
        if 'version' in config:
            version = config['version']
            if not isinstance(version, str) or not re.match(r'^\d+\.\d+(\.\d+)?$', version):
                self.add_error('version', f"版本格式无效: {version}")
        
        # 验证名称
        if 'name' in config:
            name = config['name']
            if not isinstance(name, str) or len(name.strip()) == 0:
                self.add_error('name', f"名称无效: {name}")
    
    def _validate_datasources(self, datasources: Dict[str, Any]):
        """验证数据源配置"""
        if not isinstance(datasources, dict):
            self.add_error('datasources', "数据源配置必须是字典类型")
            return
        
        for ds_name, ds_config in datasources.items():
            self._validate_single_datasource(ds_name, ds_config)
    
    def _validate_single_datasource(self, name: str, config: Dict[str, Any]):
        """验证单个数据源配置"""
        if not isinstance(config, dict):
            self.add_error(f'datasources.{name}', "数据源配置必须是字典类型")
            return
        
        # 验证类型
        if 'type' not in config:
            self.add_error(f'datasources.{name}.type', "缺少数据源类型")
        elif config['type'] not in self.SUPPORTED_DATASOURCE_TYPES:
            self.add_error(f'datasources.{name}.type', 
                          f"不支持的数据源类型: {config['type']}")
        
        # 验证连接配置
        if 'connection' not in config:
            self.add_error(f'datasources.{name}.connection', "缺少连接配置")
        elif not isinstance(config['connection'], dict):
            self.add_error(f'datasources.{name}.connection', "连接配置必须是字典类型")
    
    def _validate_steps(self, steps: List[Dict[str, Any]]):
        """验证步骤配置"""
        if not isinstance(steps, list):
            self.add_error('steps', "步骤配置必须是列表类型")
            return
        
        if len(steps) == 0:
            self.add_error('steps', "至少需要一个步骤")
            return
        
        step_names = set()
        for i, step in enumerate(steps):
            self._validate_single_step(i, step, step_names)
    
    def _validate_single_step(self, index: int, step: Dict[str, Any], step_names: set):
        """验证单个步骤配置"""
        if not isinstance(step, dict):
            self.add_error(f'steps[{index}]', "步骤配置必须是字典类型")
            return
        
        # 验证必需字段
        required_fields = ['name', 'type']
        for field in required_fields:
            if field not in step:
                self.add_error(f'steps[{index}].{field}', f"缺少必需字段: {field}")
        
        # 验证步骤名称唯一性
        if 'name' in step:
            name = step['name']
            if name in step_names:
                self.add_error(f'steps[{index}].name', f"步骤名称重复: {name}")
            else:
                step_names.add(name)
        
        # 验证步骤类型
        if 'type' in step:
            step_type = step['type']
            if step_type not in self.SUPPORTED_STEP_TYPES:
                self.add_error(f'steps[{index}].type', 
                              f"不支持的步骤类型: {step_type}")
        
        # 验证依赖关系
        if 'depends_on' in step:
            self._validate_dependencies(index, step['depends_on'], step_names)
    
    def _validate_dependencies(self, step_index: int, dependencies: List[str], 
                             available_steps: set):
        """验证步骤依赖关系"""
        if not isinstance(dependencies, list):
            self.add_error(f'steps[{step_index}].depends_on', 
                          "依赖配置必须是列表类型")
            return
        
        for dep in dependencies:
            if not isinstance(dep, str):
                self.add_error(f'steps[{step_index}].depends_on', 
                              f"依赖名称必须是字符串: {dep}")
            elif dep not in available_steps:
                self.add_error(f'steps[{step_index}].depends_on', 
                              f"引用了不存在的步骤: {dep}")
    
    def _validate_output(self, output: Dict[str, Any]):
        """验证输出配置"""
        if not isinstance(output, dict):
            self.add_error('output', "输出配置必须是字典类型")
            return
        
        # 验证输出格式
        if 'format' in output:
            supported_formats = {'json', 'csv', 'excel', 'parquet', 'sql'}
            if output['format'] not in supported_formats:
                self.add_error('output.format', 
                              f"不支持的输出格式: {output['format']}")


class DataTypeValidator(DataValidator):
    """数据类型验证器"""
    
    def validate_dataframe(self, df: pd.DataFrame, schema: Dict[str, Any]) -> bool:
        """验证 DataFrame 结构和数据"""
        self.clear_errors()
        
        if not isinstance(df, pd.DataFrame):
            self.add_error('dataframe', "输入不是有效的 DataFrame")
            return False
        
        # 验证列结构
        if 'columns' in schema:
            self._validate_columns(df, schema['columns'])
        
        # 验证数据约束
        if 'constraints' in schema:
            self._validate_constraints(df, schema['constraints'])
        
        return not self.has_errors()
    
    def _validate_columns(self, df: pd.DataFrame, column_schema: Dict[str, Any]):
        """验证列结构"""
        # 检查必需列
        if 'required' in column_schema:
            for col in column_schema['required']:
                if col not in df.columns:
                    self.add_error('columns', f"缺少必需列: {col}")
        
        # 检查列数据类型
        if 'types' in column_schema:
            for col, expected_type in column_schema['types'].items():
                if col in df.columns:
                    self._validate_column_type(df, col, expected_type)
    
    def _validate_column_type(self, df: pd.DataFrame, column: str, expected_type: str):
        """验证列数据类型"""
        actual_type = str(df[column].dtype)
        
        # 类型映射
        type_mapping = {
            'int': ['int64', 'int32', 'int16', 'int8'],
            'float': ['float64', 'float32'],
            'string': ['object', 'string'],
            'datetime': ['datetime64[ns]', 'datetime64'],
            'bool': ['bool']
        }
        
        if expected_type in type_mapping:
            if actual_type not in type_mapping[expected_type]:
                self.add_error(f'columns.{column}', 
                              f"列类型不匹配，期望: {expected_type}, 实际: {actual_type}")
    
    def _validate_constraints(self, df: pd.DataFrame, constraints: Dict[str, Any]):
        """验证数据约束"""
        # 检查非空约束
        if 'not_null' in constraints:
            for col in constraints['not_null']:
                if col in df.columns and df[col].isnull().any():
                    null_count = df[col].isnull().sum()
                    self.add_error(f'constraints.not_null.{col}', 
                                  f"列包含 {null_count} 个空值")
        
        # 检查唯一性约束
        if 'unique' in constraints:
            for col in constraints['unique']:
                if col in df.columns and df[col].duplicated().any():
                    dup_count = df[col].duplicated().sum()
                    self.add_error(f'constraints.unique.{col}', 
                                  f"列包含 {dup_count} 个重复值")
        
        # 检查值范围约束
        if 'range' in constraints:
            for col, range_config in constraints['range'].items():
                if col in df.columns:
                    self._validate_value_range(df, col, range_config)
    
    def _validate_value_range(self, df: pd.DataFrame, column: str, 
                            range_config: Dict[str, Any]):
        """验证值范围"""
        if 'min' in range_config:
            min_val = range_config['min']
            if (df[column] < min_val).any():
                violation_count = (df[column] < min_val).sum()
                self.add_error(f'constraints.range.{column}.min', 
                              f"{violation_count} 个值小于最小值 {min_val}")
        
        if 'max' in range_config:
            max_val = range_config['max']
            if (df[column] > max_val).any():
                violation_count = (df[column] > max_val).sum()
                self.add_error(f'constraints.range.{column}.max', 
                              f"{violation_count} 个值大于最大值 {max_val}")


class SchemaValidator(DataValidator):
    """Schema 验证器"""
    
    def validate_json_schema(self, data: Any, schema: Dict[str, Any]) -> bool:
        """验证 JSON Schema"""
        self.clear_errors()
        
        try:
            # 这里应该使用 jsonschema 库进行验证
            # 由于简化实现，这里只做基本验证
            self._validate_basic_schema(data, schema)
        except Exception as e:
            self.add_error('schema', f"Schema 验证失败: {str(e)}")
        
        return not self.has_errors()
    
    def _validate_basic_schema(self, data: Any, schema: Dict[str, Any]):
        """基本 Schema 验证"""
        # 验证类型
        if 'type' in schema:
            expected_type = schema['type']
            if not self._check_type(data, expected_type):
                self.add_error('type', f"类型不匹配，期望: {expected_type}")
        
        # 验证必需属性（对象类型）
        if isinstance(data, dict) and 'required' in schema:
            for field in schema['required']:
                if field not in data:
                    self.add_error('required', f"缺少必需字段: {field}")
        
        # 验证属性（对象类型）
        if isinstance(data, dict) and 'properties' in schema:
            for key, value in data.items():
                if key in schema['properties']:
                    # 递归验证子属性
                    sub_validator = SchemaValidator()
                    if not sub_validator.validate_json_schema(value, schema['properties'][key]):
                        self.errors.extend(sub_validator.get_errors())
    
    def _check_type(self, data: Any, expected_type: str) -> bool:
        """检查数据类型"""
        type_mapping = {
            'string': str,
            'number': (int, float, Decimal),
            'integer': int,
            'boolean': bool,
            'array': list,
            'object': dict,
            'null': type(None)
        }
        
        if expected_type in type_mapping:
            return isinstance(data, type_mapping[expected_type])
        
        return True


def validate_sql_injection(sql: str) -> Tuple[bool, List[str]]:
    """验证 SQL 注入风险"""
    dangerous_patterns = [
        r';\s*(drop|delete|truncate|update)\s+',
        r'union\s+select',
        r'exec\s*\(',
        r'xp_cmdshell',
        r'sp_executesql',
        r'--|#',
        r'/\*.*\*/',
        r'@@version',
        r'information_schema',
        r'sys\.',
    ]
    
    risks = []
    sql_lower = sql.lower()
    
    for pattern in dangerous_patterns:
        if re.search(pattern, sql_lower, re.IGNORECASE):
            risks.append(f"检测到潜在的 SQL 注入模式: {pattern}")
    
    return len(risks) == 0, risks


def validate_column_name(name: str) -> Tuple[bool, str]:
    """验证列名格式"""
    if not isinstance(name, str):
        return False, "列名必须是字符串"
    
    if len(name.strip()) == 0:
        return False, "列名不能为空"
    
    # 检查 SQL 保留字
    sql_keywords = {
        'select', 'from', 'where', 'group', 'order', 'by', 'having',
        'insert', 'update', 'delete', 'drop', 'create', 'alter',
        'table', 'database', 'index', 'view', 'procedure'
    }
    
    if name.lower() in sql_keywords:
        return False, f"列名不能使用 SQL 保留字: {name}"
    
    # 检查字符格式
    if not re.match(r'^[a-zA-Z][a-zA-Z0-9_]*$', name):
        return False, "列名只能包含字母、数字和下划线，且必须以字母开头"
    
    return True, ""


def validate_expression(expression: str) -> Tuple[bool, str]:
    """验证表达式安全性"""
    if not isinstance(expression, str):
        return False, "表达式必须是字符串"
    
    # 检查危险函数调用
    dangerous_functions = [
        'eval', 'exec', 'compile', '__import__',
        'open', 'file', 'input', 'raw_input',
        'reload', 'vars', 'globals', 'locals'
    ]
    
    for func in dangerous_functions:
        if func in expression:
            return False, f"表达式包含危险函数: {func}"
    
    # 检查危险属性访问
    if '__' in expression and ('__class__' in expression or '__base__' in expression):
        return False, "表达式包含危险的属性访问"
    
    return True, ""


class BusinessValidator(DataValidator):
    """业务逻辑验证器"""
    
    def validate_pivot_config(self, config: Dict[str, Any]) -> bool:
        """验证透视配置"""
        self.clear_errors()
        
        required_fields = ['index_columns', 'pivot_column', 'value_columns']
        for field in required_fields:
            if field not in config:
                self.add_error(field, f"透视配置缺少必需字段: {field}")
        
        # 验证列名列表
        for field in ['index_columns', 'value_columns']:
            if field in config:
                if not isinstance(config[field], list):
                    self.add_error(field, f"{field} 必须是列表类型")
                elif len(config[field]) == 0:
                    self.add_error(field, f"{field} 不能为空")
        
        return not self.has_errors()
    
    def validate_join_config(self, config: Dict[str, Any]) -> bool:
        """验证连接配置"""
        self.clear_errors()
        
        required_fields = ['left_on', 'right_on', 'how']
        for field in required_fields:
            if field not in config:
                self.add_error(field, f"连接配置缺少必需字段: {field}")
        
        # 验证连接类型
        if 'how' in config:
            valid_joins = {'inner', 'left', 'right', 'outer', 'cross'}
            if config['how'] not in valid_joins:
                self.add_error('how', f"不支持的连接类型: {config['how']}")
        
        return not self.has_errors()
    
    def validate_aggregation_config(self, config: Dict[str, Any]) -> bool:
        """验证聚合配置"""
        self.clear_errors()
        
        if 'group_by' not in config and 'agg_functions' not in config:
            self.add_error('config', "聚合配置必须包含 group_by 或 agg_functions")
        
        # 验证聚合函数
        if 'agg_functions' in config:
            valid_functions = {
                'sum', 'count', 'avg', 'min', 'max', 'std', 'var', 'median'
            }
            
            for col, func in config['agg_functions'].items():
                if isinstance(func, str):
                    if func not in valid_functions:
                        self.add_error('agg_functions', 
                                      f"不支持的聚合函数: {func}")
                elif isinstance(func, list):
                    for f in func:
                        if f not in valid_functions:
                            self.add_error('agg_functions', 
                                          f"不支持的聚合函数: {f}")
        
        return not self.has_errors()


# 全局验证器实例
uqm_validator = UQMValidator()
data_type_validator = DataTypeValidator()
schema_validator = SchemaValidator()
business_validator = BusinessValidator()




================================================================
End of Codebase
================================================================
